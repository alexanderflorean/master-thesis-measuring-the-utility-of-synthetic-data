{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b188d49-010e-42ff-9103-2016ef3f0f4c",
   "metadata": {},
   "source": [
    "# Step 2: Preprocessing & Classification model\n",
    "This section will load up the defined settings from the pickles directory and run the machine learning pipeline with the help of the `pycaret` library and save respective data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3185f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all packages needed in this section\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys \n",
    "\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             roc_auc_score, \n",
    "                             matthews_corrcoef,\n",
    "                             cohen_kappa_score)\n",
    "\n",
    "from pycaret.classification import *\n",
    "from pycaret.containers.models.classification import get_all_model_containers\n",
    "\n",
    "# utility functions for the experiment\n",
    "sys.path.append('../src')\n",
    "\n",
    "from mlflow_manager import MLFlowManager\n",
    "from tuning_grids import Grids\n",
    "from utils import getPicklesFromDir, getExperimentConfig, run_pycaret_setup, translate_model_name\n",
    "\n",
    "# Get global experiment settings\n",
    "config = getExperimentConfig()\n",
    "folders = config['folders']\n",
    "# get a list of all settings for the datasets prepared beforehand\n",
    "dataset_settings = getPicklesFromDir(folders['settings_dir'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3938c0",
   "metadata": {},
   "source": [
    "dataset_settings pickle is saved as follows:\n",
    "```\n",
    "\"meta_data\": meta_dataset,  # contains information about the dataset, including path\n",
    "\"setup_param\": setup_param, # contains all the setup parameters for pycaret setup() function\n",
    "\"sdg_param\": sdg_param,     # contains all sdg parameters for the CTGAN() function\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cd7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the dataset to save the performance. Initially was going to use mlflow for this. \n",
    "However, a bugg surfaced when google colab was used, where it got stuck in a endless loop\n",
    "trying to read the loggs via the colab cell. Thus this implementation.\n",
    "\n",
    "Columns:\n",
    "    Dataset id: str\n",
    "        the dataset id that the model was evaluated on.\n",
    "    model: str\n",
    "        the shortend model name/id (e.g. lr = logistic regression, rf = random forest, etc.)\n",
    "    F1, Accuracy, AUC: float\n",
    "        performance metrics from evaluating the model on the hold-out data.\n",
    "    Params: dict\n",
    "        the hyperparameters for the model.\n",
    "    Tuned on: str\n",
    "        wheter the hyperparameters comes from tuning on original data or synthetic\n",
    "    Trained on: str\n",
    "        the type of data that the model was trained on, \"original\" or \"synthetic\"\n",
    "    Quality: str\n",
    "        if synthetic, the quality id of the generator\n",
    "    SDG:\n",
    "        the synthetic genenerator id.\n",
    "    Dataset type: str\n",
    "        if the dataset that the model trained on is \"original\" or \"synthetic\"\n",
    "    USI: str\n",
    "        Unique Settings Identifier, a unique string generated by pycaret setup each initialization\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Create an empty DataFrame with the specified columns\n",
    "columns = [\"Dataset id\", \"model\", \"F1\", \"Accuracy\", \"AUC\", \"MCC\", \"Kappa\", \"Params\", \"Tuned on\", \"Trained on\", \"USI\", \"Quality\", \"SDG\"]\n",
    "model_performance_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "performance_row = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc371f77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d5c5b_row8_col1, #T_d5c5b_row10_col1, #T_d5c5b_row15_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d5c5b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d5c5b_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_d5c5b_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d5c5b_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_d5c5b_row0_col1\" class=\"data row0 col1\" >592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d5c5b_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_d5c5b_row1_col1\" class=\"data row1 col1\" >Outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d5c5b_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_d5c5b_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d5c5b_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_d5c5b_row3_col1\" class=\"data row3 col1\" >(768, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d5c5b_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_d5c5b_row4_col1\" class=\"data row4 col1\" >(768, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d5c5b_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_d5c5b_row5_col1\" class=\"data row5 col1\" >(614, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d5c5b_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_d5c5b_row6_col1\" class=\"data row6 col1\" >(154, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d5c5b_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_d5c5b_row7_col1\" class=\"data row7 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d5c5b_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_d5c5b_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d5c5b_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_d5c5b_row9_col1\" class=\"data row9 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d5c5b_row10_col0\" class=\"data row10 col0\" >Normalize</td>\n",
       "      <td id=\"T_d5c5b_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d5c5b_row11_col0\" class=\"data row11 col0\" >Normalize method</td>\n",
       "      <td id=\"T_d5c5b_row11_col1\" class=\"data row11 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d5c5b_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_d5c5b_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d5c5b_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_d5c5b_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d5c5b_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_d5c5b_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d5c5b_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_d5c5b_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d5c5b_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_d5c5b_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d5c5b_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_d5c5b_row17_col1\" class=\"data row17 col1\" >D0-Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5c5b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d5c5b_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_d5c5b_row18_col1\" class=\"data row18 col1\" >d579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x200b04e6c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>23:14:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   23:14:24\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .        Logistic Regression"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb7761c27fa44a3a59769b46213eca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "run_dataset = config['run_dataset']\n",
    "\n",
    "for settings in dataset_settings:\n",
    "        \n",
    "    if run_dataset is not None and settings['meta']['id'] not in run_dataset:\n",
    "        # Checks if run_dataset contains dataset_id's\n",
    "        # if it does, run the experiment only on specified datasets\n",
    "        continue\n",
    "        \n",
    "    # get path\n",
    "    dataset_path = f\"{folders['real_dir']}{settings['meta']['filename']}\"\n",
    "    # run setup function\n",
    "    s = run_pycaret_setup(dataset_path, settings['setup_param'])\n",
    "    \n",
    "    USI = s.get_config('USI')\n",
    "    \n",
    "    # Init experiment logging\n",
    "    experiment_name = f\"{settings['meta']['id']}-{settings['meta']['name']}\"\n",
    "    mlflow = MLFlowManager(experiment_name)\n",
    "    \n",
    "    logg_tags = {\n",
    "        'Dataset id': settings['meta']['id'],\n",
    "        'Tuned on': 'original',\n",
    "        'Trained on': 'original',\n",
    "        'USI': USI,\n",
    "    }\n",
    "    \n",
    "    mlflow.start_run(mlflow.run_name_with_original_data, tags=logg_tags)\n",
    "    \n",
    "    # for each defined model in the global config\n",
    "    # create specified model and tune it\n",
    "    for ml_model in config['clf']['ml_models']:\n",
    "        \n",
    "        model_name = f\"{settings['meta']['id']}-{translate_model_name(ml_model)}\"\n",
    "        \n",
    "        logg_tags['model']=ml_model\n",
    "        \n",
    "        mlflow.start_run(model_name, tags=logg_tags, nested=True)\n",
    "\n",
    "        # create & tune model\n",
    "        #model = s.create_model(ml_model)\n",
    "        \n",
    "        #Quickfix for efficiency\n",
    "        all_models = get_all_model_containers(s)\n",
    "        model = all_models[ml_model].class_def()\n",
    "        \n",
    "        tune_grid = Grids.get_tuning_grid(ml_model)\n",
    "        \n",
    "        tuned_model = s.tune_model(model, **config['clf']['tuning_param'], custom_grid=tune_grid)\n",
    "        \n",
    "        # get validation results\n",
    "        val_df = s.pull()\n",
    "        val_score = {}\n",
    "        val_score['val_Accuracy'] = val_df['Accuracy']['Mean']\n",
    "        val_score['val_F1'] = val_df['F1']['Mean']\n",
    "        #val_score['AUC']      = val_df['AUC']['Mean']\n",
    "        #val_score['Kappa']    = val_df['Kappa']['Mean']\n",
    "        #val_score['MCC']      = val_df['MCC']['Mean']\n",
    "        \n",
    "        \n",
    "        # get the performance on the holdout data\n",
    "        y_test = s.get_config('y_test')\n",
    "        pred_model = s.predict_model(estimator=tuned_model)\n",
    "        y_pred = pred_model['prediction_label']\n",
    "\n",
    "        metrics =  classification_report(y_true=y_test, y_pred=y_pred, output_dict=True, digits=4)\n",
    "        holdout_score = pd.DataFrame.from_dict(metrics).transpose()\n",
    "\n",
    "        test_metrics = {\n",
    "            \"Accuracy\": metrics['accuracy'],\n",
    "            \"F1\": metrics['macro avg']['f1-score'],\n",
    "            \"MCC\": matthews_corrcoef(y_true=y_test, y_pred=y_pred),\n",
    "            \"Kappa\": cohen_kappa_score(y1=y_test, y2=y_pred)\n",
    "        }\n",
    "\n",
    "        # If there is a prediction_score in the from predict_model (sometimes there isn't)\n",
    "        if 'prediction_score' in pred_model.columns:\n",
    "            y_pred_score = pred_model['prediction_score']\n",
    "            # If multiclass classification, set argument multi_class='one-vs-one'\n",
    "            if y_test.nunique() > 2:\n",
    "                m_class = 'ovo'\n",
    "            else:\n",
    "                m_class = 'raise'\n",
    "            test_metrics['AUC'] = roc_auc_score(y_true=y_test, y_score=y_pred_score, multi_class=m_class)\n",
    "\n",
    "\n",
    "        \n",
    "        # log parameters     \n",
    "        mlflow.log_params(tuned_model.get_params())\n",
    "        # log performance\n",
    "        mlflow.log_tag('model', ml_model)\n",
    "        mlflow.log_metrics(test_metrics)\n",
    "        mlflow.log_metrics(val_score)\n",
    "        mlflow.log_score_report_to_html(val_df, \"Validation\")\n",
    "        mlflow.log_score_report_to_html(holdout_score, \"Holdout\")\n",
    "        # log model\n",
    "        mlflow.log_model(model=tuned_model)\n",
    "        # end run for the model\n",
    "        mlflow.end_run()\n",
    "        \n",
    "        # quick fix for colab issue\n",
    "        performance_row = {**logg_tags, **test_metrics}\n",
    "        performance_row['Params'] = tuned_model.get_params()\n",
    "        model_performance_df = model_performance_df.append(performance_row, ignore_index=True)\n",
    "\n",
    "        \n",
    "    # Save model details on the model with best performance under the the 'Original data models' run\n",
    "    # Note: Error with google colab, ends up in infinite run when get_best_run_by_metric is called\n",
    "    # So far, found that it is unable to read the files for getting the data?\n",
    "    \n",
    "    ## Fix, dont use mlfow to get the best run, instead, save them into a regular file\n",
    "    \"\"\" Removed for mlflow\n",
    "    run_id = mlflow.get_active_run_id()\n",
    "    best_run = mlflow.get_best_nested_run_by_metric(parent_run_id=run_id, metric_name=\"F1\")\n",
    "    # save under the \"parent\" run\n",
    "    mlflow.log_params(best_run.data.params)\n",
    "    mlflow.log_metrics(best_run.data.metrics)\n",
    "    mlflow.log_tag('model run name', best_run.data.tags['mlflow.runName'])\n",
    "    mlflow.log_tag('model', best_run.data.tags['model'])\n",
    "    mlflow.log_tag('TrainedOn', 'original')\n",
    "    mlflow.log_tag('Dataset ID', best_run.data.tags['Dataset ID'])\n",
    "    mlflow.log_tag('model run id', best_run.info.run_id)\n",
    "    \"\"\"\n",
    "\n",
    "    # end run for this dataset\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Save model performance to csv\n",
    "model_performance_df.to_csv(folders['model_perf_filepath'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0373980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%notify\n",
    "\n",
    "### Testing that the provided hyperparameters work with pycaret and the system\n",
    "#settings = dataset_settings[0]\n",
    "#dataset_path = f\"{folders['real_dir']}{settings['meta']['filename']}\"\n",
    "#s = run_pycaret_setup(dataset_path, settings['setup_param'])\n",
    "#for ml_model in ['rf', 'gbc', 'mlp']: #config['clf']['ml_models']:\n",
    "#    # create & tune model\n",
    "#    #model = s.create_model(ml_model)\n",
    "#    #Quickfix for efficiency\n",
    "#    all_models = get_all_model_containers(s)\n",
    "#    model = all_models[ml_model].class_def()\n",
    "\n",
    "#    tune_grid = Grids.get_tuning_grid(ml_model)\n",
    "#    tuned_model = s.tune_model(model, \n",
    "#                               **config['clf']['tuning_param'], \n",
    "#                               custom_grid=tune_grid\n",
    "#                              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.16 (Master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "163px",
    "width": "322px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
