{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74485887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long the whole notebook took to run\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b188d49-010e-42ff-9103-2016ef3f0f4c",
   "metadata": {},
   "source": [
    "# Step 2: Preprocessing & Classification model\n",
    "This section will load up the defined settings from the pickles directory and run the machine learning pipeline with the help of the `pycaret` library and save respective data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3185f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all packages needed in this section\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from pycaret.classification import *\n",
    "\n",
    "# utility functions for the experiment\n",
    "sys.path.append('../src')\n",
    "\n",
    "from mlflow_manager import MLFlowManager\n",
    "from tuning_grids import Grids\n",
    "from utils import getPicklesFromDir, getExperimentConfig, run_pycaret_setup, translate_model_name\n",
    "\n",
    "# Get global experiment settings\n",
    "config = getExperimentConfig()\n",
    "folders = config['folders']\n",
    "# get a list of all settings for the datasets prepared beforehand\n",
    "dataset_settings = getPicklesFromDir(folders['settings_dir'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3938c0",
   "metadata": {},
   "source": [
    "dataset_settings pickle is saved as follows:\n",
    "```\n",
    "\"meta_data\": meta_dataset,  # contains information about the dataset, including path\n",
    "\"setup_param\": setup_param, # contains all the setup parameters for pycaret setup() function\n",
    "\"sdg_param\": sdg_param,     # contains all sdg parameters for the CTGAN() function\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc371f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d6283_row8_col1, #T_d6283_row12_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d6283\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d6283_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_d6283_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d6283_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_d6283_row0_col1\" class=\"data row0 col1\" >6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d6283_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_d6283_row1_col1\" class=\"data row1 col1\" >Outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d6283_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_d6283_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d6283_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_d6283_row3_col1\" class=\"data row3 col1\" >(768, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d6283_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_d6283_row4_col1\" class=\"data row4 col1\" >(768, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d6283_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_d6283_row5_col1\" class=\"data row5 col1\" >(614, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d6283_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_d6283_row6_col1\" class=\"data row6 col1\" >(154, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d6283_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_d6283_row7_col1\" class=\"data row7 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d6283_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_d6283_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d6283_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_d6283_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d6283_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_d6283_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d6283_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_d6283_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d6283_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_d6283_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d6283_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_d6283_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d6283_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_d6283_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d6283_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_d6283_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d6283_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_d6283_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d6283_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_d6283_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d6283_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_d6283_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d6283_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_d6283_row19_col1\" class=\"data row19 col1\" >D0-Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6283_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_d6283_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_d6283_row20_col1\" class=\"data row20 col1\" >442c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bcd1100e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6c749_row10_col0, #T_6c749_row10_col1, #T_6c749_row10_col2, #T_6c749_row10_col3, #T_6c749_row10_col4, #T_6c749_row10_col5, #T_6c749_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6c749\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6c749_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_6c749_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_6c749_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_6c749_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_6c749_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_6c749_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_6c749_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6c749_row0_col0\" class=\"data row0 col0\" >0.8065</td>\n",
       "      <td id=\"T_6c749_row0_col1\" class=\"data row0 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row0_col2\" class=\"data row0 col2\" >0.5000</td>\n",
       "      <td id=\"T_6c749_row0_col3\" class=\"data row0 col3\" >0.9167</td>\n",
       "      <td id=\"T_6c749_row0_col4\" class=\"data row0 col4\" >0.6471</td>\n",
       "      <td id=\"T_6c749_row0_col5\" class=\"data row0 col5\" >0.5291</td>\n",
       "      <td id=\"T_6c749_row0_col6\" class=\"data row0 col6\" >0.5753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6c749_row1_col0\" class=\"data row1 col0\" >0.6935</td>\n",
       "      <td id=\"T_6c749_row1_col1\" class=\"data row1 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row1_col2\" class=\"data row1 col2\" >0.5455</td>\n",
       "      <td id=\"T_6c749_row1_col3\" class=\"data row1 col3\" >0.5714</td>\n",
       "      <td id=\"T_6c749_row1_col4\" class=\"data row1 col4\" >0.5581</td>\n",
       "      <td id=\"T_6c749_row1_col5\" class=\"data row1 col5\" >0.3238</td>\n",
       "      <td id=\"T_6c749_row1_col6\" class=\"data row1 col6\" >0.3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6c749_row2_col0\" class=\"data row2 col0\" >0.6290</td>\n",
       "      <td id=\"T_6c749_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row2_col2\" class=\"data row2 col2\" >0.5000</td>\n",
       "      <td id=\"T_6c749_row2_col3\" class=\"data row2 col3\" >0.4783</td>\n",
       "      <td id=\"T_6c749_row2_col4\" class=\"data row2 col4\" >0.4889</td>\n",
       "      <td id=\"T_6c749_row2_col5\" class=\"data row2 col5\" >0.1980</td>\n",
       "      <td id=\"T_6c749_row2_col6\" class=\"data row2 col6\" >0.1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6c749_row3_col0\" class=\"data row3 col0\" >0.6452</td>\n",
       "      <td id=\"T_6c749_row3_col1\" class=\"data row3 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row3_col2\" class=\"data row3 col2\" >0.8182</td>\n",
       "      <td id=\"T_6c749_row3_col3\" class=\"data row3 col3\" >0.5000</td>\n",
       "      <td id=\"T_6c749_row3_col4\" class=\"data row3 col4\" >0.6207</td>\n",
       "      <td id=\"T_6c749_row3_col5\" class=\"data row3 col5\" >0.3221</td>\n",
       "      <td id=\"T_6c749_row3_col6\" class=\"data row3 col6\" >0.3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6c749_row4_col0\" class=\"data row4 col0\" >0.7869</td>\n",
       "      <td id=\"T_6c749_row4_col1\" class=\"data row4 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row4_col2\" class=\"data row4 col2\" >0.3810</td>\n",
       "      <td id=\"T_6c749_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_6c749_row4_col4\" class=\"data row4 col4\" >0.5517</td>\n",
       "      <td id=\"T_6c749_row4_col5\" class=\"data row4 col5\" >0.4466</td>\n",
       "      <td id=\"T_6c749_row4_col6\" class=\"data row4 col6\" >0.5362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6c749_row5_col0\" class=\"data row5 col0\" >0.7213</td>\n",
       "      <td id=\"T_6c749_row5_col1\" class=\"data row5 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row5_col2\" class=\"data row5 col2\" >0.3810</td>\n",
       "      <td id=\"T_6c749_row5_col3\" class=\"data row5 col3\" >0.6667</td>\n",
       "      <td id=\"T_6c749_row5_col4\" class=\"data row5 col4\" >0.4848</td>\n",
       "      <td id=\"T_6c749_row5_col5\" class=\"data row5 col5\" >0.3128</td>\n",
       "      <td id=\"T_6c749_row5_col6\" class=\"data row5 col6\" >0.3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6c749_row6_col0\" class=\"data row6 col0\" >0.6885</td>\n",
       "      <td id=\"T_6c749_row6_col1\" class=\"data row6 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row6_col2\" class=\"data row6 col2\" >0.7143</td>\n",
       "      <td id=\"T_6c749_row6_col3\" class=\"data row6 col3\" >0.5357</td>\n",
       "      <td id=\"T_6c749_row6_col4\" class=\"data row6 col4\" >0.6122</td>\n",
       "      <td id=\"T_6c749_row6_col5\" class=\"data row6 col5\" >0.3607</td>\n",
       "      <td id=\"T_6c749_row6_col6\" class=\"data row6 col6\" >0.3712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6c749_row7_col0\" class=\"data row7 col0\" >0.7049</td>\n",
       "      <td id=\"T_6c749_row7_col1\" class=\"data row7 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row7_col2\" class=\"data row7 col2\" >0.5714</td>\n",
       "      <td id=\"T_6c749_row7_col3\" class=\"data row7 col3\" >0.5714</td>\n",
       "      <td id=\"T_6c749_row7_col4\" class=\"data row7 col4\" >0.5714</td>\n",
       "      <td id=\"T_6c749_row7_col5\" class=\"data row7 col5\" >0.3464</td>\n",
       "      <td id=\"T_6c749_row7_col6\" class=\"data row7 col6\" >0.3464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6c749_row8_col0\" class=\"data row8 col0\" >0.7869</td>\n",
       "      <td id=\"T_6c749_row8_col1\" class=\"data row8 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row8_col2\" class=\"data row8 col2\" >0.4286</td>\n",
       "      <td id=\"T_6c749_row8_col3\" class=\"data row8 col3\" >0.9000</td>\n",
       "      <td id=\"T_6c749_row8_col4\" class=\"data row8 col4\" >0.5806</td>\n",
       "      <td id=\"T_6c749_row8_col5\" class=\"data row8 col5\" >0.4609</td>\n",
       "      <td id=\"T_6c749_row8_col6\" class=\"data row8 col6\" >0.5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_6c749_row9_col0\" class=\"data row9 col0\" >0.6230</td>\n",
       "      <td id=\"T_6c749_row9_col1\" class=\"data row9 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row9_col2\" class=\"data row9 col2\" >0.2857</td>\n",
       "      <td id=\"T_6c749_row9_col3\" class=\"data row9 col3\" >0.4286</td>\n",
       "      <td id=\"T_6c749_row9_col4\" class=\"data row9 col4\" >0.3429</td>\n",
       "      <td id=\"T_6c749_row9_col5\" class=\"data row9 col5\" >0.0931</td>\n",
       "      <td id=\"T_6c749_row9_col6\" class=\"data row9 col6\" >0.0968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_6c749_row10_col0\" class=\"data row10 col0\" >0.7086</td>\n",
       "      <td id=\"T_6c749_row10_col1\" class=\"data row10 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row10_col2\" class=\"data row10 col2\" >0.5126</td>\n",
       "      <td id=\"T_6c749_row10_col3\" class=\"data row10 col3\" >0.6569</td>\n",
       "      <td id=\"T_6c749_row10_col4\" class=\"data row10 col4\" >0.5459</td>\n",
       "      <td id=\"T_6c749_row10_col5\" class=\"data row10 col5\" >0.3393</td>\n",
       "      <td id=\"T_6c749_row10_col6\" class=\"data row10 col6\" >0.3659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c749_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_6c749_row11_col0\" class=\"data row11 col0\" >0.0635</td>\n",
       "      <td id=\"T_6c749_row11_col1\" class=\"data row11 col1\" >0.0000</td>\n",
       "      <td id=\"T_6c749_row11_col2\" class=\"data row11 col2\" >0.1524</td>\n",
       "      <td id=\"T_6c749_row11_col3\" class=\"data row11 col3\" >0.1955</td>\n",
       "      <td id=\"T_6c749_row11_col4\" class=\"data row11 col4\" >0.0839</td>\n",
       "      <td id=\"T_6c749_row11_col5\" class=\"data row11 col5\" >0.1203</td>\n",
       "      <td id=\"T_6c749_row11_col6\" class=\"data row11 col6\" >0.1413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bccec48cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>02:39:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   02:39:45\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .        SVM - Linear Kernel"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'actual_estimator' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 379, in set_params\n    result = super().set_params(**kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\pipeline.py\", line 188, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 72, in _set_params\n    super().set_params(**params)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\base.py\", line 258, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\base.py\", line 246, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'C' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'].\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 381, in set_params\n    result = self._final_estimator.set_params(**kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\base.py\", line 246, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'actual_estimator' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mcreate_model(ml_model)\n\u001b[0;32m     33\u001b[0m tune_grid \u001b[38;5;241m=\u001b[39m Grids\u001b[38;5;241m.\u001b[39mget_tuning_grid(ml_model)\n\u001b[1;32m---> 34\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mtune_model(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuning_param\u001b[39m\u001b[38;5;124m'\u001b[39m], custom_grid\u001b[38;5;241m=\u001b[39mtune_grid)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# get validation results\u001b[39;00m\n\u001b[0;32m     37\u001b[0m val_df \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mpull()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\classification\\oop.py:1572\u001b[0m, in \u001b[0;36mClassificationExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1382\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1401\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \n\u001b[0;32m   1570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1573\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1574\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1575\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1576\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1577\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1578\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1579\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1580\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1581\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1582\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1583\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1584\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1585\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1586\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1587\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1588\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1589\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1590\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1591\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1592\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:2663\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   2661\u001b[0m             model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m   2662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2663\u001b[0m     model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m   2664\u001b[0m best_params \u001b[38;5;241m=\u001b[39m model_grid\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m   2665\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\searchcv.py:408\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[0;32m    406\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m--> 408\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# Feed the point and objective value back into optimizer\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Optimizer minimizes objective, hence provide negative score\u001b[39;00m\n\u001b[0;32m    411\u001b[0m local_results \u001b[38;5;241m=\u001b[39m all_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(params):]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\concurrent\\futures\\_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'actual_estimator' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "for settings in dataset_settings:\n",
    "    # get path\n",
    "    dataset_path = f\"{folders['real_dir']}{settings['meta']['filename']}\"\n",
    "    # run setup function\n",
    "    s = run_pycaret_setup(dataset_path, settings['setup_param'])\n",
    "    \n",
    "    USI = s.get_config('USI')\n",
    "\n",
    "    \n",
    "    # Init experiment logging\n",
    "    experiment_name = f\"{settings['meta']['id']}-{settings['meta']['name']}\"\n",
    "    mlflow = MLFlowManager(experiment_name)\n",
    "    \n",
    "    logg_tags = {\n",
    "        'USI': USI,\n",
    "        'Dataset ID': settings['meta']['id'],\n",
    "        'Dataset Type': 'original'\n",
    "    }\n",
    "    \n",
    "    mlflow.start_run(\"Original data models\", tags=logg_tags)\n",
    "    \n",
    "    # for each defined model in the global config\n",
    "    # create specified model and tune it\n",
    "    for ml_model in config['clf']['ml_models']:\n",
    "        \n",
    "        model_name = f\"{settings['meta']['id']}-{translate_model_name(ml_model)}\"\n",
    "        logg_tags['model']=ml_model\n",
    "        \n",
    "        mlflow.start_run(model_name, tags=logg_tags, nested=True)\n",
    "\n",
    "        # create & tune model\n",
    "        model = s.create_model(ml_model)\n",
    "        \n",
    "        tune_grid = Grids.get_tuning_grid(ml_model)\n",
    "        \n",
    "        tuned_model = s.tune_model(model, **config['clf']['tuning_param'], custom_grid=tune_grid)\n",
    "        \n",
    "        # get validation results\n",
    "        val_df = s.pull()\n",
    "        val_score = {}\n",
    "        val_score['Accuracy'] = val_df['Accuracy']['Mean']\n",
    "        val_score['F1-score'] = val_df['F1']['Mean']\n",
    "        val_score['AUC']      = val_df['AUC']['Mean']\n",
    "        val_score['Kappa']    = val_df['Kappa']['Mean']\n",
    "        val_score['MCC']      = val_df['MCC']['Mean']\n",
    "        \n",
    "        # test the model on the holdout-data\n",
    "        holdout_score = s.predict_model(estimator=tuned_model)\n",
    "        #metrics =  classification_report(y_true=y_test, y_pred=y_pred, output_dict=True, digits=4)\n",
    "        #metrics_df = pd.DataFrame(metrics).transpose()\n",
    "        \n",
    "        # log parameters     \n",
    "        mlflow.log_params(tuned_model.get_params())\n",
    "        # log performance\n",
    "        mlflow.log_metrics(val_score)\n",
    "        mlflow.log_score_report_to_html(val_df, \"Validation\")\n",
    "        mlflow.log_score_report_to_html(holdout_score, \"Holdout\")\n",
    "        # log model\n",
    "        mlflow.log_model(model=tuned_model)\n",
    "        \n",
    "        mlflow.end_run()\n",
    "        \n",
    "    # Save model details on the model with best accurracy under the the 'Original data models' run\n",
    "    best_run = mlflow.get_best_run_by_metric(metric_name='Accuracy')\n",
    "    \n",
    "    mlflow.log_params(best_run.data.params)\n",
    "    mlflow.log_metrics(best_run.data.metrics)\n",
    "    mlflow.log_tag('model run name', best_run.data.tags['mlflow.runName'])\n",
    "    mlflow.log_tag('model', best_run.data.tags['model'])\n",
    "    mlflow.log_tag('model run id', best_run.info.run_id)\n",
    "    \n",
    "    mlflow.end_run()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2192e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>02:46:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   02:46:17\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .        SVM - Linear Kernel"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c835bbca2446a28ba558c8847119e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'actual_estimator' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 379, in set_params\n    result = super().set_params(**kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\pipeline.py\", line 188, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 72, in _set_params\n    super().set_params(**params)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\base.py\", line 258, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\base.py\", line 246, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'C' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'].\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 381, in set_params\n    result = self._final_estimator.set_params(**kwargs)\n  File \"C:\\Users\\flore\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\base.py\", line 246, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'actual_estimator' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#import numpy as np\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tune_grid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m----> 3\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mtune_model(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuning_param\u001b[39m\u001b[38;5;124m'\u001b[39m], custom_grid\u001b[38;5;241m=\u001b[39mtune_grid)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\classification\\oop.py:1572\u001b[0m, in \u001b[0;36mClassificationExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1382\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1401\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \n\u001b[0;32m   1570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1573\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1574\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1575\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1576\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1577\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1578\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1579\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1580\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1581\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1582\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1583\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1584\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1585\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1586\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1587\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1588\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1589\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1590\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1591\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1592\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:2663\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   2661\u001b[0m             model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m   2662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2663\u001b[0m     model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m   2664\u001b[0m best_params \u001b[38;5;241m=\u001b[39m model_grid\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m   2665\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\searchcv.py:408\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[0;32m    406\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m--> 408\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# Feed the point and objective value back into optimizer\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Optimizer minimizes objective, hence provide negative score\u001b[39;00m\n\u001b[0;32m    411\u001b[0m local_results \u001b[38;5;241m=\u001b[39m all_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(params):]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\concurrent\\futures\\_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'actual_estimator' for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n              power_t=0.5, random_state=6636, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False). Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "tune_grid['C'] = np.logspace(-3,2,20).tolist()\n",
    "tuned_model = s.tune_model(model, **config['clf']['tuning_param'], custom_grid=tune_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abf6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Time to run the whole notebook: {int(round(end_time-start_time, 0))} seconds\")\n",
    "print(f\"Time to run the whole notebook: {round((end_time-start_time)/60, 1)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_run.data.tags['mlflow.runName']\n",
    "mlflow.get_best_run_by_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738bfd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_tag('Best model run name', mlflow.get_run_name(best_run))\n",
    "mlflow.log_tag('model', mlflow.get_model_tag(best_run))\n",
    "mlflow.log_tag('Best model run id', best_run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb7492",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notice \n",
    "Following cells until end of section (i.e. section 3.0) contains experimental code that will not be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cf1ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Following shows which are models are natively available in the pycaret library\n",
    "# It is possible to add estimators\n",
    "all_models = models()\n",
    "display(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927410f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Need to define param that should be explored, define which method e.g. grid_search vs random vs optuna\n",
    "# default search method: random grid search\n",
    "# Todo: lookup default search range parameters\n",
    "\n",
    "# uses the best model to optimze\n",
    "#tuned = tune_model(clf, optimize='Accuracy', n_iter=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.16 (Master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "163px",
    "width": "322px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
