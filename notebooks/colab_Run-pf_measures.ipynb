{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264,"status":"ok","timestamp":1683166080111,"user":{"displayName":"Alexander Florean","userId":"14511975951874661105"},"user_tz":-120},"id":"tczLfte5VsTQ","outputId":"efba7aad-ad64-4ba2-f5b7-77bd68d63a79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May  4 02:07:59 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"id":"tczLfte5VsTQ"},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":57,"status":"ok","timestamp":1683166080573,"user":{"displayName":"Alexander Florean","userId":"14511975951874661105"},"user_tz":-120},"id":"kpgjzmmnVudM","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"736ccef3-1854-4c83-b016-212533fb3484"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntry:\\n  import cuml\\nexcept (ImportError, KeyError, ModuleNotFoundError):\\n  !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\\n  !python rapidsai-csp-utils/colab/pip-install.py\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n","# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n","\"\"\"\n","try:\n","  import cuml\n","except (ImportError, KeyError, ModuleNotFoundError):\n","  !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","  !python rapidsai-csp-utils/colab/pip-install.py\n","\"\"\"\n"],"id":"kpgjzmmnVudM"},{"cell_type":"code","source":["# check if cuda is installed correctly\n","#!nvcc --version"],"metadata":{"id":"SUjaR-8Mf_Ck","executionInfo":{"status":"ok","timestamp":1683166080574,"user_tz":-120,"elapsed":56,"user":{"displayName":"Alexander Florean","userId":"14511975951874661105"}}},"id":"SUjaR-8Mf_Ck","execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2290,"status":"ok","timestamp":1683166082810,"user":{"displayName":"Alexander Florean","userId":"14511975951874661105"},"user_tz":-120},"id":"QowwN3rg3o2t","outputId":"45a3421f-13da-4866-e095-aa4cd95249d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Othercomputers/ThinkPad/master-thesis-vt23\n"]}],"source":["# Mount google drive to colab and change to correct directory\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/Othercomputers/ThinkPad/master-thesis-vt23"],"id":"QowwN3rg3o2t"},{"cell_type":"code","source":["# Quickfix for dependencies in colab\n","# Try to import packages, if exception is thrown install dependencies and kill runtime\n","%cd /content/drive/Othercomputers/ThinkPad/master-thesis-vt23\n","try:\n","  from pycaret.classification import *\n","except (ImportError, KeyError, ModuleNotFoundError):\n","  ## code to install dependencies\n","  !pip install -r colab_requirements.txt\n","  #!pip install pomegranate==0.14.8  #needed for sdmetrics BNLikelihood metric\n","  display('Stopping RUNTIME! Colaboratory will restart automatically. Please run again.')\n","  import os\n","  os.kill(os.getpid(), 9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPINkwgyf2zy","executionInfo":{"status":"ok","timestamp":1683166089574,"user_tz":-120,"elapsed":6812,"user":{"displayName":"Alexander Florean","userId":"14511975951874661105"}},"outputId":"77055a64-218f-48a8-f097-2dc9ece25023"},"id":"BPINkwgyf2zy","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ThinkPad/master-thesis-vt23\n"]}]},{"cell_type":"code","source":["%cd /content/drive/Othercomputers/ThinkPad/master-thesis-vt23/notebooks\n","%run -t Step3-SDG.ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cgMBmYA8WF2E","outputId":"e6d37290-54cd-4272-ad78-2648731db6f1"},"id":"cgMBmYA8WF2E","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ThinkPad/master-thesis-vt23/notebooks\n"]},{"output_type":"display_data","data":{"text/plain":["'Start: SDG-D305Q3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["#START#\n","SD305Q3\n","Epoch 1, Loss G:  13.8811,Loss D: -23.1722\n","Epoch 2, Loss G:  28.8966,Loss D: -59.2696\n","Epoch 3, Loss G:  38.7769,Loss D: -90.7842\n","Epoch 4, Loss G:  38.5299,Loss D: -102.0367\n","Epoch 5, Loss G:  28.5205,Loss D: -108.3986\n","Epoch 6, Loss G:  18.7792,Loss D: -105.8290\n","Epoch 7, Loss G:  9.9350,Loss D: -106.9323\n","Epoch 8, Loss G:  5.4390,Loss D: -98.8265\n","Epoch 9, Loss G:  1.6427,Loss D: -97.6762\n","Epoch 10, Loss G: -1.8819,Loss D: -93.8329\n","Epoch 11, Loss G: -4.0833,Loss D: -90.7783\n","Epoch 12, Loss G: -9.6581,Loss D: -87.7790\n","Epoch 13, Loss G: -10.8246,Loss D: -77.5848\n","Epoch 14, Loss G: -14.8608,Loss D: -84.0826\n","Epoch 15, Loss G: -15.8249,Loss D: -77.0118\n","Epoch 16, Loss G: -26.7353,Loss D: -71.9521\n","Epoch 17, Loss G: -27.5851,Loss D: -65.4362\n","Epoch 18, Loss G: -23.0196,Loss D: -67.4935\n","Epoch 19, Loss G: -26.2745,Loss D: -65.1893\n","Epoch 20, Loss G: -36.7731,Loss D: -59.3050\n","Epoch 21, Loss G: -34.3330,Loss D: -64.0883\n","Epoch 22, Loss G: -32.1643,Loss D: -62.1118\n","Epoch 23, Loss G: -34.4557,Loss D: -47.7960\n","Epoch 24, Loss G: -39.3503,Loss D: -43.8728\n","Epoch 25, Loss G: -41.3573,Loss D: -41.8141\n","Epoch 26, Loss G: -37.3828,Loss D: -43.8271\n","Epoch 27, Loss G: -34.5638,Loss D: -44.9454\n","Epoch 28, Loss G: -40.0141,Loss D: -38.9534\n","Epoch 29, Loss G: -38.2909,Loss D: -41.3584\n","Epoch 30, Loss G: -39.9304,Loss D: -37.0018\n","Epoch 31, Loss G: -41.7740,Loss D: -29.1509\n","Epoch 32, Loss G: -43.9884,Loss D: -23.8728\n","Epoch 33, Loss G: -37.7548,Loss D: -29.1453\n","Epoch 34, Loss G: -41.6971,Loss D: -24.6026\n","Epoch 35, Loss G: -44.0467,Loss D: -21.6593\n","Epoch 36, Loss G: -38.9380,Loss D: -25.7580\n","Epoch 37, Loss G: -43.0256,Loss D: -18.9735\n","Epoch 38, Loss G: -38.2388,Loss D: -18.6324\n","Epoch 39, Loss G: -42.2564,Loss D: -13.2842\n","Epoch 40, Loss G: -41.3757,Loss D: -19.9319\n","Epoch 41, Loss G: -37.1345,Loss D: -9.3733\n","Epoch 42, Loss G: -36.5754,Loss D: -25.1524\n","Epoch 43, Loss G: -38.6679,Loss D: -11.4654\n","Epoch 44, Loss G: -38.4342,Loss D: -18.8083\n","Epoch 45, Loss G: -35.9885,Loss D: -7.4292\n","Epoch 46, Loss G: -38.4000,Loss D: -11.1706\n","Epoch 47, Loss G: -37.7231,Loss D: -9.5453\n","Epoch 48, Loss G: -31.3769,Loss D: -14.5226\n","Epoch 49, Loss G: -36.1767,Loss D: -2.9176\n","Epoch 50, Loss G: -41.3766,Loss D: -8.9738\n","Epoch 51, Loss G: -33.5656,Loss D: -10.6970\n","Epoch 52, Loss G: -36.9052,Loss D: -7.9827\n","Epoch 53, Loss G: -33.7122,Loss D: -0.2961\n","Epoch 54, Loss G: -29.8500,Loss D: -6.5588\n","Epoch 55, Loss G: -26.1810,Loss D: -7.2716\n","Epoch 56, Loss G: -30.4472,Loss D: -14.2519\n","Epoch 57, Loss G: -29.1467,Loss D: -7.2773\n","Epoch 58, Loss G: -33.0505,Loss D: -7.3288\n","Epoch 59, Loss G: -22.6079,Loss D:  8.2709\n","Epoch 60, Loss G: -27.9684,Loss D:  1.1482\n","Epoch 61, Loss G: -27.5654,Loss D: -1.6254\n","Epoch 62, Loss G: -25.0186,Loss D: -4.6327\n","Epoch 63, Loss G: -22.0773,Loss D:  0.4559\n","Epoch 64, Loss G: -28.0397,Loss D: -0.5443\n","Epoch 65, Loss G: -30.5937,Loss D: -4.5828\n","Epoch 66, Loss G: -23.4050,Loss D: -3.8578\n","Epoch 67, Loss G: -25.6485,Loss D: -6.0789\n","Epoch 68, Loss G: -23.1611,Loss D:  5.5075\n","Epoch 69, Loss G: -22.5577,Loss D:  0.0676\n","Epoch 70, Loss G: -23.1046,Loss D: -3.4286\n","Epoch 71, Loss G: -24.6236,Loss D:  6.3514\n","Epoch 72, Loss G: -21.3209,Loss D: -1.1180\n","Epoch 73, Loss G: -20.9502,Loss D: -11.3526\n","Epoch 74, Loss G: -23.8447,Loss D:  2.1166\n","Epoch 75, Loss G: -20.4783,Loss D: -1.7198\n","Epoch 76, Loss G: -18.0510,Loss D: -0.2945\n","Epoch 77, Loss G: -16.4041,Loss D: -3.6385\n","Epoch 78, Loss G: -15.9487,Loss D: -5.6511\n","Epoch 79, Loss G: -13.3504,Loss D: -1.1689\n","Epoch 80, Loss G: -13.1618,Loss D: -3.3921\n","Epoch 81, Loss G: -15.7322,Loss D: -5.2589\n","Epoch 82, Loss G: -12.1950,Loss D:  4.6272\n","Epoch 83, Loss G: -18.4679,Loss D: -3.1961\n","Epoch 84, Loss G: -11.2111,Loss D: -0.1141\n","Epoch 85, Loss G: -13.0659,Loss D: -2.8039\n","Epoch 86, Loss G: -14.0935,Loss D:  1.1684\n","Epoch 87, Loss G: -12.8171,Loss D: -7.6253\n","Epoch 88, Loss G: -15.4166,Loss D:  4.5991\n","Epoch 89, Loss G: -15.0635,Loss D:  5.8100\n","Epoch 90, Loss G: -11.2748,Loss D: -1.9129\n","Epoch 91, Loss G: -9.0216,Loss D:  0.6610\n","Epoch 92, Loss G: -9.8244,Loss D: -8.9744\n","Epoch 93, Loss G: -7.3600,Loss D: -2.9897\n","Epoch 94, Loss G: -10.2024,Loss D:  4.2584\n","Epoch 95, Loss G: -7.9409,Loss D: -3.4046\n","Epoch 96, Loss G: -4.5180,Loss D: -0.1262\n","Epoch 97, Loss G: -5.0832,Loss D:  1.4205\n","Epoch 98, Loss G: -8.3517,Loss D: -2.1196\n","Epoch 99, Loss G: -9.9512,Loss D:  0.1482\n","Epoch 100, Loss G: -2.2507,Loss D:  0.9547\n","Epoch 101, Loss G: -4.8883,Loss D:  0.7762\n","Epoch 102, Loss G: -4.8294,Loss D:  2.0055\n","Epoch 103, Loss G: -4.5716,Loss D:  0.3492\n","Epoch 104, Loss G: -4.0818,Loss D:  4.7252\n","Epoch 105, Loss G:  1.7301,Loss D:  0.2402\n","Epoch 106, Loss G: -6.7618,Loss D: -4.7352\n","Epoch 107, Loss G: -3.0188,Loss D:  3.1683\n","Epoch 108, Loss G:  3.1316,Loss D:  0.5216\n","Epoch 109, Loss G:  1.6602,Loss D:  0.0676\n","Epoch 110, Loss G: -1.6662,Loss D: -0.2872\n","Epoch 111, Loss G: -3.8391,Loss D: -0.7856\n","Epoch 112, Loss G:  1.1941,Loss D: -5.1130\n","Epoch 113, Loss G: -4.0312,Loss D:  0.8220\n","Epoch 114, Loss G: -0.3959,Loss D:  0.5697\n","Epoch 115, Loss G: -1.8430,Loss D: -2.3287\n","Epoch 116, Loss G: -5.3939,Loss D: -2.1558\n","Epoch 117, Loss G: -1.8319,Loss D: -1.7280\n","Epoch 118, Loss G: -1.2158,Loss D: -3.8521\n","Epoch 119, Loss G:  1.6140,Loss D:  1.0819\n","Epoch 120, Loss G: -7.0733,Loss D:  6.4612\n","Epoch 121, Loss G: -5.4217,Loss D:  6.4909\n","Epoch 122, Loss G:  0.4351,Loss D: -2.0761\n","Epoch 123, Loss G: -2.2594,Loss D:  1.5531\n","Epoch 124, Loss G:  2.1552,Loss D: -2.3557\n","Epoch 125, Loss G: -0.7447,Loss D: -0.7030\n","Epoch 126, Loss G: -0.4764,Loss D:  0.9733\n","Epoch 127, Loss G:  1.2827,Loss D:  1.9935\n","Epoch 128, Loss G: -1.7340,Loss D: -7.3793\n","Epoch 129, Loss G: -2.3083,Loss D: -3.1156\n","Epoch 130, Loss G:  1.1901,Loss D:  0.8647\n","Epoch 131, Loss G: -0.1369,Loss D:  5.8375\n","Epoch 132, Loss G: -1.8327,Loss D: -0.6784\n","Epoch 133, Loss G: -0.2982,Loss D: -1.7668\n","Epoch 134, Loss G: -1.1780,Loss D:  6.2450\n","Epoch 135, Loss G: -0.5587,Loss D: -2.2702\n","Epoch 136, Loss G: -0.4569,Loss D: -1.3850\n","Epoch 137, Loss G: -1.3467,Loss D:  2.4126\n","Epoch 138, Loss G: -1.1608,Loss D:  0.3863\n","Epoch 139, Loss G: -1.9463,Loss D:  4.5631\n","Epoch 140, Loss G: -1.2386,Loss D:  1.7852\n","Epoch 141, Loss G: -2.1466,Loss D:  2.5480\n","Epoch 142, Loss G:  1.6219,Loss D: -2.9995\n","Epoch 143, Loss G: -1.3706,Loss D:  3.2800\n","Epoch 144, Loss G:  0.4035,Loss D: -3.3510\n","Epoch 145, Loss G: -0.0229,Loss D: -4.6998\n","Epoch 146, Loss G: -1.2600,Loss D: -2.5957\n","Epoch 147, Loss G: -3.4225,Loss D:  2.3713\n","Epoch 148, Loss G:  5.7504,Loss D:  2.8152\n","Epoch 149, Loss G: -1.7016,Loss D: -3.8492\n","Epoch 150, Loss G:  1.0715,Loss D:  0.5322\n","Epoch 151, Loss G: -0.3939,Loss D: -1.0377\n","Epoch 152, Loss G: -8.0527,Loss D:  1.1945\n","Epoch 153, Loss G:  0.6752,Loss D: -7.9420\n","Epoch 154, Loss G: -6.6544,Loss D: -3.1671\n","Epoch 155, Loss G:  1.0815,Loss D:  0.1876\n","Epoch 156, Loss G:  2.1413,Loss D:  2.5558\n","Epoch 157, Loss G:  1.6525,Loss D: -3.1930\n","Epoch 158, Loss G: -0.5202,Loss D: -0.0269\n","Epoch 159, Loss G: -3.1308,Loss D: -1.0260\n","Epoch 160, Loss G:  4.0886,Loss D: -1.0874\n","Epoch 161, Loss G:  0.3175,Loss D:  1.5955\n","Epoch 162, Loss G:  0.7420,Loss D:  5.2290\n","Epoch 163, Loss G:  6.2608,Loss D: -4.2811\n","Epoch 164, Loss G: -2.1281,Loss D: -3.7405\n","Epoch 165, Loss G:  1.9364,Loss D:  1.6906\n","Epoch 166, Loss G:  4.8652,Loss D: -3.8029\n","Epoch 167, Loss G:  1.2286,Loss D: -3.3728\n","Epoch 168, Loss G: -1.1838,Loss D:  5.4920\n","Epoch 169, Loss G:  7.6844,Loss D: -3.5197\n","Epoch 170, Loss G: -4.8704,Loss D: -0.7247\n","Epoch 171, Loss G: -2.4813,Loss D: -6.1162\n","Epoch 172, Loss G:  2.1380,Loss D:  3.5897\n","Epoch 173, Loss G:  0.4065,Loss D: -3.5694\n","Epoch 174, Loss G:  3.9101,Loss D: -6.1834\n","Epoch 175, Loss G:  0.2017,Loss D:  2.6890\n","Epoch 176, Loss G:  2.6384,Loss D:  2.0075\n","Epoch 177, Loss G:  3.8576,Loss D:  3.8050\n","Epoch 178, Loss G:  0.8600,Loss D: -6.1498\n","Epoch 179, Loss G:  3.7796,Loss D: -3.1684\n","Epoch 180, Loss G: -0.4039,Loss D: -4.2438\n","Epoch 181, Loss G: -0.7328,Loss D: -2.4862\n","Epoch 182, Loss G: -2.3171,Loss D:  3.1454\n","Epoch 183, Loss G:  1.9771,Loss D: -9.4801\n","Epoch 184, Loss G:  3.3106,Loss D: -11.4670\n","Epoch 185, Loss G:  2.6637,Loss D: -1.3330\n","Epoch 186, Loss G:  0.1290,Loss D: -3.6434\n","Epoch 187, Loss G:  4.4406,Loss D:  0.0104\n","Epoch 188, Loss G:  5.3436,Loss D: -3.1416\n","Epoch 189, Loss G: -1.4634,Loss D:  4.7431\n","Epoch 190, Loss G:  4.9309,Loss D: -6.5333\n","Epoch 191, Loss G:  1.7155,Loss D: -4.1314\n","Epoch 192, Loss G:  1.5494,Loss D: -7.9783\n","Epoch 193, Loss G:  0.8705,Loss D: -1.7281\n","Epoch 194, Loss G: -1.2638,Loss D: -2.3501\n","Epoch 195, Loss G:  2.0091,Loss D: -7.2234\n","Epoch 196, Loss G: -1.5700,Loss D:  0.3084\n","Epoch 197, Loss G:  2.8264,Loss D: -6.0993\n","Epoch 198, Loss G:  8.0623,Loss D: -6.3471\n","Epoch 199, Loss G:  2.0429,Loss D: -5.3745\n","Epoch 200, Loss G:  1.6004,Loss D: -1.0692\n","Epoch 201, Loss G:  4.7288,Loss D: -10.8609\n","Epoch 202, Loss G:  2.1038,Loss D: -8.9279\n","Epoch 203, Loss G: -0.2608,Loss D: -6.8176\n","Epoch 204, Loss G:  3.8896,Loss D: -5.3161\n","Epoch 205, Loss G:  2.6874,Loss D: -6.9934\n","Epoch 206, Loss G: -0.0409,Loss D:  0.9445\n","Epoch 207, Loss G: -2.5657,Loss D: -8.4081\n","Epoch 208, Loss G:  1.5485,Loss D: -4.5394\n","Epoch 209, Loss G:  7.3128,Loss D: -1.0373\n","Epoch 210, Loss G: -2.3418,Loss D: -1.7092\n","Epoch 211, Loss G:  0.2007,Loss D: -11.8987\n","Epoch 212, Loss G: -0.5687,Loss D: -4.5340\n","Epoch 213, Loss G: -1.5381,Loss D: -12.4869\n","Epoch 214, Loss G:  2.8862,Loss D: -10.4085\n","Epoch 215, Loss G: -0.6274,Loss D: -6.8834\n","Epoch 216, Loss G:  0.4425,Loss D: -13.0699\n","Epoch 217, Loss G:  1.4441,Loss D: -12.1141\n","Epoch 218, Loss G:  3.7590,Loss D: -6.9744\n","Epoch 219, Loss G:  3.6745,Loss D: -0.5091\n","Epoch 220, Loss G:  6.6632,Loss D: -7.7835\n","Epoch 221, Loss G:  4.8820,Loss D: -3.9242\n","Epoch 222, Loss G:  1.2585,Loss D: -3.3362\n","Epoch 223, Loss G:  1.0240,Loss D: -4.7835\n","Epoch 224, Loss G:  4.6202,Loss D: -7.3609\n","Epoch 225, Loss G:  1.9542,Loss D:  0.8946\n","Epoch 226, Loss G: -0.6555,Loss D: -14.2195\n","Epoch 227, Loss G:  1.6077,Loss D: -2.8364\n","Epoch 228, Loss G: -1.0349,Loss D: -4.2286\n","Epoch 229, Loss G:  1.4319,Loss D: -1.9919\n","Epoch 230, Loss G:  1.2921,Loss D: -7.6366\n","Epoch 231, Loss G:  0.9948,Loss D: -2.2265\n","Epoch 232, Loss G: -2.3936,Loss D: -2.9613\n","Epoch 233, Loss G: -1.6367,Loss D: -7.1547\n","Epoch 234, Loss G: -0.5086,Loss D:  1.2405\n","Epoch 235, Loss G:  2.4562,Loss D: -4.8002\n","Epoch 236, Loss G:  0.9662,Loss D: -10.2219\n","Epoch 237, Loss G:  5.5912,Loss D: -7.6475\n","Epoch 238, Loss G:  1.7797,Loss D: -3.9587\n","Epoch 239, Loss G:  4.5151,Loss D: -2.3506\n","Epoch 240, Loss G:  3.1028,Loss D: -2.4880\n","Epoch 241, Loss G: -1.8915,Loss D: -6.1805\n","Epoch 242, Loss G: -5.0929,Loss D: -2.5076\n","Epoch 243, Loss G: -1.7878,Loss D: -2.4614\n","Epoch 244, Loss G:  0.1911,Loss D: -6.8559\n","Epoch 245, Loss G:  0.2840,Loss D: -10.4553\n","Epoch 246, Loss G: -1.5327,Loss D: -7.8430\n","Epoch 247, Loss G: -2.7143,Loss D: -6.4189\n","Epoch 248, Loss G:  0.9103,Loss D: -3.5541\n","Epoch 249, Loss G: -2.9095,Loss D: -2.7379\n","Epoch 250, Loss G:  1.6740,Loss D: -4.5201\n","Epoch 251, Loss G: -0.5315,Loss D:  0.9124\n","Epoch 252, Loss G:  6.4296,Loss D: -0.8294\n","Epoch 253, Loss G: -0.1510,Loss D: -2.9241\n","Epoch 254, Loss G: -0.4729,Loss D:  0.8606\n","Epoch 255, Loss G:  0.7853,Loss D: -2.9768\n","Epoch 256, Loss G: -3.8056,Loss D: -2.9883\n","Epoch 257, Loss G: -1.8671,Loss D: -4.3811\n","Epoch 258, Loss G: -7.4445,Loss D:  3.8150\n","Epoch 259, Loss G: -5.0760,Loss D: -1.0258\n","Epoch 260, Loss G:  3.1253,Loss D: -4.8928\n","Epoch 261, Loss G: -3.2358,Loss D: -0.4824\n","Epoch 262, Loss G: -0.8227,Loss D: -2.3630\n","Epoch 263, Loss G: -8.3221,Loss D: -9.0084\n","Epoch 264, Loss G: -5.5812,Loss D: -2.0109\n","Epoch 265, Loss G: -2.5096,Loss D:  1.5427\n","Epoch 266, Loss G: -2.3252,Loss D: -5.6499\n","Epoch 267, Loss G: -5.4296,Loss D: -10.6670\n","Epoch 268, Loss G: -0.4668,Loss D:  4.6010\n","Epoch 269, Loss G: -2.3269,Loss D: -11.7624\n","Epoch 270, Loss G:  0.3810,Loss D: -1.5206\n","Epoch 271, Loss G: -2.9053,Loss D: -1.4817\n","Epoch 272, Loss G: -3.8094,Loss D:  2.1635\n","Epoch 273, Loss G: -1.2165,Loss D: -0.2318\n","Epoch 274, Loss G: -2.0107,Loss D:  0.8515\n","Epoch 275, Loss G: -2.2313,Loss D: -0.7063\n","Epoch 276, Loss G: -4.7015,Loss D: -3.5042\n","Epoch 277, Loss G:  1.4374,Loss D: -5.5478\n","Epoch 278, Loss G: -0.9372,Loss D: -2.0495\n","Epoch 279, Loss G: -2.1266,Loss D: -4.7891\n","Epoch 280, Loss G: -1.6310,Loss D: -5.2635\n","Epoch 281, Loss G: -0.0702,Loss D: -2.7657\n","Epoch 282, Loss G:  0.6528,Loss D: -3.3236\n","Epoch 283, Loss G: -1.7704,Loss D: -4.9751\n","Epoch 284, Loss G:  0.4344,Loss D: -6.6665\n","Epoch 285, Loss G: -0.6117,Loss D:  0.7454\n","Epoch 286, Loss G: -5.3765,Loss D: -6.5443\n","Epoch 287, Loss G: -6.6881,Loss D: -1.6051\n","Epoch 288, Loss G: -3.8473,Loss D: -5.5712\n","Epoch 289, Loss G: -4.5242,Loss D:  1.3658\n","Epoch 290, Loss G: -6.2750,Loss D: -7.7518\n","Epoch 291, Loss G: -6.4789,Loss D:  3.8718\n","Epoch 292, Loss G: -5.5871,Loss D: -7.3635\n","Epoch 293, Loss G: -4.3119,Loss D: -3.1107\n","Epoch 294, Loss G: -5.2032,Loss D: -7.0216\n","Epoch 295, Loss G: -7.6813,Loss D: -4.0417\n","Epoch 296, Loss G: -1.9440,Loss D: -3.8413\n","Epoch 297, Loss G: -5.0043,Loss D: -3.9642\n","Epoch 298, Loss G: -3.9869,Loss D: -4.5607\n","Epoch 299, Loss G: -3.7240,Loss D: -0.2005\n","Epoch 300, Loss G:  3.8305,Loss D: -4.6930\n","Epoch 301, Loss G: -6.1738,Loss D: -5.8552\n","Epoch 302, Loss G: -4.7661,Loss D: -2.1885\n","Epoch 303, Loss G: -1.3270,Loss D: -4.9649\n","Epoch 304, Loss G: -7.3758,Loss D:  1.5087\n","Epoch 305, Loss G: -1.5810,Loss D: -1.0747\n","Epoch 306, Loss G: -4.3057,Loss D:  3.4047\n","Epoch 307, Loss G: -1.9060,Loss D: -8.2059\n","Epoch 308, Loss G: -4.0758,Loss D: -1.6195\n","Epoch 309, Loss G: -2.1888,Loss D: -4.8091\n","Epoch 310, Loss G: -9.3913,Loss D:  4.6873\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"decdc74c"},"outputs":[],"source":["#%cd /content/drive/Othercomputers/ThinkPad/master-thesis-vt23/notebooks\n","#%run -t Step2-Model-GPU.ipynb"],"id":"decdc74c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6530530"},"outputs":[],"source":["#%cd /content/drive/Othercomputers/ThinkPad/master-thesis-vt23/notebooks\n","#%run -t Step4-SD_models.ipynb"],"id":"c6530530"},{"cell_type":"code","execution_count":null,"metadata":{"id":"073ed9a9"},"outputs":[],"source":["#%cd /content/drive/Othercomputers/ThinkPad/master-thesis-vt23/notebooks\n","#%run -t Step5-Measures_PF.ipynb"],"id":"073ed9a9"},{"cell_type":"markdown","metadata":{"id":"eIUerwpLugkX"},"source":["Below are cells tested for making the colab notebook work. They are not needed, but saved here incase."],"id":"eIUerwpLugkX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtG4JfxtjSx1"},"outputs":[],"source":["\"\"\"\n","!pip install pycaret\n","!pip install pandas-profiling\n","!pip install sdv\n","!pip install sdmetrics\n","!pip install seaborn\n","!pip install mlflow\n","!pip install scikit-optimize\n","!pip install autopep8\n","!pip install autoviz\n","!pip install kmodes\n","!pip install pomegranate==0.14.8\n","%cd notebooks\n","\"\"\""],"id":"QtG4JfxtjSx1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvTCBldxbNR0"},"outputs":[],"source":["\"\"\"\n","#Deprecated\n","import sys\n","sys.path.append('/usr/local/lib/python3.9/site-packages/')\n","###Downloads conda installer and makes it runnable\n","#! wget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.1.0-1-Linux-x86_64.sh\n","#! chmod +x Miniconda3-py39_23.1.0-1-Linux-x86_64.sh\n","\n","! bash ./Miniconda3-py39_23.1.0-1-Linux-x86_64.sh -b -f -p /usr/local\n","!conda init\n","\"\"\""],"id":"kvTCBldxbNR0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aykRbesWPfX"},"outputs":[],"source":["#Deprecated\n","#%cd /content/drive/Othercomputers/ThinkPad/master-thesis-vt23\n","#!conda update -y conda -n base\n","#!conda create -y -n master python=3.9.16\n","#!conda activate master\n","#!conda env update -f requirements.yaml -n master\n","#!conda run -n master python -m ipykernel install --user --name master"],"id":"6aykRbesWPfX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjO0olTaLKz_"},"outputs":[],"source":["#!pip freeze > ../colab_requirements.txt"],"id":"KjO0olTaLKz_"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1z_7FwgUwT4GhRgml5ndwauw7a49s5kZy","timestamp":1682767096261}],"history_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":5}