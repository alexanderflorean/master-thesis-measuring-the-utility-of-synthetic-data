{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f91a5bf",
   "metadata": {},
   "source": [
    "## SDG\n",
    "The synthetic data is generated for each specified pickle object in '../pickles/settings'\n",
    "that uses datasets in the folder '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03cee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports for the section\n",
    "from sdv.tabular import CTGAN\n",
    "\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import os \n",
    "import sys \n",
    "\n",
    "#TODO, use YML config file\n",
    "sys.path.append('../src')\n",
    "from utils import getPicklesFromDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1753dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'meta_data': {'name': 'D0-Diabetes',\n",
       "   'id': 'D0',\n",
       "   'path': '../data/diabetes.csv',\n",
       "   'target': 'Outcome',\n",
       "   'ordinal_features': None,\n",
       "   'numeric_features': ['DiabetesPedigreeFunction',\n",
       "    'BMI',\n",
       "    'Insulin',\n",
       "    'Glucose',\n",
       "    'Age',\n",
       "    'SkinThickness',\n",
       "    'BloodPressure',\n",
       "    'Pregnancies'],\n",
       "   'text_features': None,\n",
       "   'categorical_features': None},\n",
       "  'setup_param': {'target': 'Outcome',\n",
       "   'train_size': 0.8,\n",
       "   'fold_strategy': 'stratifiedkfold',\n",
       "   'fold': 10,\n",
       "   'ordinal_features': None,\n",
       "   'numeric_features': ['DiabetesPedigreeFunction',\n",
       "    'BMI',\n",
       "    'Insulin',\n",
       "    'Glucose',\n",
       "    'Age',\n",
       "    'SkinThickness',\n",
       "    'BloodPressure',\n",
       "    'Pregnancies'],\n",
       "   'text_features': None,\n",
       "   'categorical_features': None,\n",
       "   'imputation_type': 'simple',\n",
       "   'numeric_imputation': 'mean',\n",
       "   'categorical_imputation': 'mode',\n",
       "   'iterative_imputation_iters': 10,\n",
       "   'numeric_iterative_imputer': 'lightgbm',\n",
       "   'categorical_iterative_imputer': 'lightgbm',\n",
       "   'text_features_method': 'tf-idf',\n",
       "   'max_encoding_ohe': 25,\n",
       "   'encoding_method': None,\n",
       "   'low_variance_threshold': None,\n",
       "   'remove_multicollinearity': False,\n",
       "   'multicollinearity_threshold': 0.01,\n",
       "   'bin_numeric_features': None,\n",
       "   'remove_outliers': False,\n",
       "   'outliers_method': 'iforest',\n",
       "   'outliers_threshold': 0.05,\n",
       "   'fix_imbalance': False,\n",
       "   'fix_imbalance_method': 'SMOTE',\n",
       "   'transformation': False,\n",
       "   'transformation_method': 'yeo-johnson',\n",
       "   'normalize': True,\n",
       "   'normalize_method': 'zscore',\n",
       "   'pca': False,\n",
       "   'pca_method': 'linear',\n",
       "   'pca_components': None,\n",
       "   'feature_selection': False,\n",
       "   'feature_selection_method': 'classic',\n",
       "   'feature_selection_estimator': 'lightbm',\n",
       "   'n_features_to_select': 0.2,\n",
       "   'log_experiment': 'mlflow',\n",
       "   'experiment_name': 'log_D0',\n",
       "   'system_log': '../logs/log_D0',\n",
       "   'log_plots': False,\n",
       "   'log_data': False,\n",
       "   'n_jobs': -1,\n",
       "   'use_gpu': False,\n",
       "   'html': True,\n",
       "   'verbose': True,\n",
       "   'profile': False,\n",
       "   'preprocess': True},\n",
       "  'sdg_param': {'primary_key': 'Outcome'}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: use YML config file\n",
    "dataset_settings  = getPicklesFromDir('../pickles/settings/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99556087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the SDG parameters that decide synthetic data of varying quality\n",
    "\n",
    "# TODO: further define settings, this prob is not enough\n",
    "quality_params = {\n",
    "    \"Q1\": {'epochs': 10, 'batch_size': 10},\n",
    "    \"Q2\": {'epochs': 50, 'batch_size': 50},\n",
    "#    \"Q3\": {'epochs': 250, 'batch_size': 500},\n",
    "#    \"Q4\": {'epochs': 1250, 'batch_size': 1000},\n",
    "} \n",
    "\n",
    "\n",
    "#TODO: move to experiment_settings\n",
    "\n",
    "sd_size_factor = 1  # (int), factor for number of rows to generate for each setting,\n",
    "                       # size * len(original_datset)\n",
    "                       # i.e. 2 means double the num of samples in the original dataset\n",
    "\n",
    "#TODO: move to experiment_settings\n",
    "\n",
    "num_SD = 2  # decides how many synthetic datasets to generate for each setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3386a32",
   "metadata": {},
   "source": [
    "Psuedo code:\n",
    "\n",
    "```\n",
    "for each pickle (setting):\n",
    "    for each varying quality:\n",
    "        create model with sdg_param and quality\n",
    "        train model with original_data\n",
    "        generate num_SD synthetic datasets with:\n",
    "            num_rows=SD_size_by_factor * len(original_dataset)\n",
    "        \n",
    "        save synthetic dataset in dataset folder\n",
    "        save SDG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee2797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD0Q1_0\n",
      "SD0Q1_1\n",
      "SD0Q2_0\n",
      "SD0Q2_1\n"
     ]
    }
   ],
   "source": [
    "# Used to just experiment with SDG name\n",
    "for quality in quality_params:\n",
    "    for itr in range(num_SD):\n",
    "\n",
    "        # creates the SDG name, using datset id, quality key, and itr number \n",
    "        # e.g. SD1Q1_2 means SDG trained on datset D1 with quality Q1 and copy num 2\n",
    "        sdg_name = f\"S{dataset_settings[0]['meta_data']['id']}{quality}_{str(itr)}\"\n",
    "        print(sdg_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18d024",
   "metadata": {},
   "source": [
    "Following cell runs the generation of synthetic data, then saves the SDG model and the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d89d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run SDG generation\n",
    "for settings in dataset_settings:\n",
    "    # for each dataset specific settings\n",
    "    \n",
    "    # load original dataset\n",
    "    original_data = pd.read_csv(settings['meta_data']['path'])  \n",
    "    \n",
    "    # get the size for generated synthetic data\n",
    "    original_data_size = len(original_data)\n",
    "    sd_size = original_data_size * sd_size_factor\n",
    "    \n",
    "    # loop through the different quality parameters for the SDG\n",
    "    for quality in quality_params:\n",
    "        \n",
    "        # create num_SD SDGs and synthetic datasets for validating results\n",
    "        for itr in range(num_SD):\n",
    "            \n",
    "            # creates model with sdg_param and quality_param as parameters\n",
    "            model = CTGAN(**settings['sdg_param'], **quality_params[quality])\n",
    "            model.fit(original_data)\n",
    "            \n",
    "            # generate synthetic data\n",
    "            synthetic_data = model.sample(num_rows=sd_size)\n",
    "            \n",
    "            # creates SDG model name, using datset id, quality key, and itr number \n",
    "            # e.g. SD1Q1_2 means SDG trained on datset D1 with quality Q1 and copy num 2\n",
    "            sdg_name = f\"S{dataset_settings[0]['meta_data']['id']}{quality}_{str(itr)}\"\n",
    "            \n",
    "            # save the synthetic dataset\n",
    "            synthetic_data.to_csv(f\"../data/{sdg_name}.csv\")\n",
    "            # saves the model using cloudpickle\n",
    "            model.save(f\"../pickles/SDGs/{sdg_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04aea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytho 3.9.16 (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
