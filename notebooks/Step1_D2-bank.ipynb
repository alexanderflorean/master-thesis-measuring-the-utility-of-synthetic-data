{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2262fa3c",
   "metadata": {},
   "source": [
    "# Step 1: Data preperation, D2-bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c385f05a-34b6-4e23-88bd-aaf61d5b1355",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw/.gitkeep'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/bank-full.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/bank-names.txt'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/bank.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/bank.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/dataset_us_diabetes.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/diabetes.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/health-insurance.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/mnist.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/titanic.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/mnist\\\\mnist_test.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/mnist\\\\mnist_train.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# Display all available datsets\n",
    "for dirname, _, filenames in os.walk('../data/raw/'):\n",
    "    for filename in filenames:\n",
    "        display(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577d340b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from utils import getExperimentConfig\n",
    "\n",
    "# Get global experiment settings\n",
    "config = getExperimentConfig()\n",
    "folders = config['folders']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24021710",
   "metadata": {},
   "source": [
    "In this section the data will be examined for selecting the preprocessing and model of the original dataset. This pipeline of preprocessing will then be save for executing on the respective synthetic dataset.\n",
    "\n",
    "\n",
    "This section will be done independently for each dataset that will be explored, with the hopes that rest of the steps of the experiment can be automized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "891ae13c-3e7a-4db1-bcf5-23511fc4ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 29.2 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_filename = \"bank-full.csv\"\n",
    "data_id = \"D2\"\n",
    "data_name = \"bank\"\n",
    "data = pd.read_csv(f\"{folders['raw_dir']}{data_filename}\", sep=';')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "display(data.info(verbose=True, memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7a34db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   age        45211 non-null  uint8   \n",
      " 1   job        45211 non-null  category\n",
      " 2   marital    45211 non-null  category\n",
      " 3   education  45211 non-null  category\n",
      " 4   default    45211 non-null  category\n",
      " 5   balance    45211 non-null  int64   \n",
      " 6   housing    45211 non-null  category\n",
      " 7   loan       45211 non-null  category\n",
      " 8   contact    45211 non-null  category\n",
      " 9   day        45211 non-null  uint8   \n",
      " 10  month      45211 non-null  category\n",
      " 11  duration   45211 non-null  int64   \n",
      " 12  campaign   45211 non-null  uint16  \n",
      " 13  pdays      45211 non-null  int16   \n",
      " 14  previous   45211 non-null  uint16  \n",
      " 15  poutcome   45211 non-null  category\n",
      " 16  y          45211 non-null  category\n",
      "dtypes: category(10), int16(1), int64(2), uint16(2), uint8(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set cols_dtype for optimized memory usage\n",
    "cols_dtype = {\n",
    "    'age': 'uint8',  # Numeric, not exceeding 255\n",
    "    'job': 'category',  # Categorical\n",
    "    'marital': 'category',  # Categorical\n",
    "    'education': 'category',  # Categorical\n",
    "    'default': 'category',  # Binary, treated as categorical\n",
    "    'balance': 'int64',  # Numeric (may include negative values)\n",
    "    'housing': 'category',  # Binary, treated as categorical\n",
    "    'loan': 'category',  # Binary, treated as categorical\n",
    "    'contact': 'category',  # Categorical\n",
    "    'day': 'uint8',  # Numeric, not exceeding 31\n",
    "    'month': 'category',  # Categorical (treated as categorical since it's not ordinal in this context)\n",
    "    'duration': 'int64',  # Numeric (may include negative values)\n",
    "    'campaign': 'uint16',  # Numeric, non-negative\n",
    "    'pdays': 'int16',  # Numeric (may include -1)\n",
    "    'previous': 'uint16',  # Numeric, non-negative\n",
    "    'poutcome': 'category',  # Categorical\n",
    "    'y': 'category'  # Binary, treated as categorical\n",
    "}\n",
    "\n",
    "\n",
    "data = pd.read_csv(f\"{folders['raw_dir']}{data_filename}\", sep=';', dtype=cols_dtype)\n",
    "data.info(verbose=True, memory_usage='deep')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b377cc",
   "metadata": {},
   "source": [
    "Saved more than 20 MB by defining cols_dtyp, while still retaining all information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc312c12-16c2-477e-a70e-497f1b9518ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>45211.0</td>\n",
       "      <td>40.94</td>\n",
       "      <td>10.62</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>45211.0</td>\n",
       "      <td>1362.27</td>\n",
       "      <td>3044.77</td>\n",
       "      <td>-8019.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>102127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>45211.0</td>\n",
       "      <td>15.81</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>45211.0</td>\n",
       "      <td>258.16</td>\n",
       "      <td>257.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>4918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>45211.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>45211.0</td>\n",
       "      <td>40.20</td>\n",
       "      <td>100.13</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>45211.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count     mean      std     min    25%    50%     75%       max\n",
       "age       45211.0    40.94    10.62    18.0   33.0   39.0    48.0      95.0\n",
       "balance   45211.0  1362.27  3044.77 -8019.0   72.0  448.0  1428.0  102127.0\n",
       "day       45211.0    15.81     8.32     1.0    8.0   16.0    21.0      31.0\n",
       "duration  45211.0   258.16   257.53     0.0  103.0  180.0   319.0    4918.0\n",
       "campaign  45211.0     2.76     3.10     1.0    1.0    2.0     3.0      63.0\n",
       "pdays     45211.0    40.20   100.13    -1.0   -1.0   -1.0    -1.0     871.0\n",
       "previous  45211.0     0.58     2.30     0.0    0.0    0.0     0.0     275.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61da477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from pycaret.classification import *\n",
    "\n",
    "# run eda\n",
    "#s = setup(data, target='y', verbose=True)\n",
    "#eda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32014532-f04b-4b0e-8f4d-266a2f004857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e820fb4f634fd98e0ee6ac62e3517b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d5bd8dac584c75a30c99f7c6669be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ProfileReport(data, minimal=True, explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a165e1-13a6-486d-beac-4b7aaec44a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Null values: ===\\n\")\n",
    "display(data.isnull().sum())\n",
    "print(\"\\n=== Data types: === \\n\")\n",
    "display(data.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71465b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'yes' with True and 'no' with False \n",
    "data['default'] = data['default'].replace({'yes': True, 'no': False})\n",
    "data['housing'] = data['housing'].replace({'yes': True, 'no': False})\n",
    "data['loan'] = data['loan'].replace({'yes': True, 'no': False})\n",
    "# replace target label with 1 0 instead of True False\n",
    "data['y'] = data['y'].replace({'yes': 1, 'no': 0})\n",
    "\n",
    "#update boolean columns\n",
    "cols_dtype['default'] = 'boolean'\n",
    "cols_dtype['housing'] = 'boolean'\n",
    "cols_dtype['loan'] = 'boolean'\n",
    "cols_dtype['y'] = 'category'\n",
    "\n",
    "display(data.head())\n",
    "display(data.info(verbose=True, memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f6372",
   "metadata": {},
   "source": [
    "### Define metadata for the dataset\n",
    "The following cells in this section is for defining the dataset specific settings that are needed to run the following experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650870f",
   "metadata": {},
   "source": [
    "> NOTICE:\n",
    "*The meta dictionary gets updated in Step 3: SDG, where metadata about each synthetic data that is generated on the respective real data. Data is appended to 'sd_meta_list' key.\n",
    "This is then saved over the current settings.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata for the SDG\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16dbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metadata & validate\n",
    "display(metadata)\n",
    "\n",
    "display(metadata.validate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf930693",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.update_column(\n",
    "    column_name='age',\n",
    "    sdtype='numerical',\n",
    "    computer_representation='UInt8')\n",
    "metadata.update_column(\n",
    "    column_name='job',\n",
    "    sdtype='categorical')\n",
    "metadata.update_column(\n",
    "    column_name='marital',\n",
    "    sdtype='categorical')\n",
    "metadata.update_column(\n",
    "    column_name='education',\n",
    "    sdtype='categorical')\n",
    "metadata.update_column(\n",
    "    column_name='default',\n",
    "    sdtype='boolean')\n",
    "metadata.update_column(\n",
    "    column_name='balance',\n",
    "    sdtype='numerical',\n",
    "    computer_representation='Int64')\n",
    "metadata.update_column(\n",
    "    column_name='housing',\n",
    "    sdtype='boolean')\n",
    "metadata.update_column(\n",
    "    column_name='loan',\n",
    "    sdtype='boolean')\n",
    "metadata.update_column(\n",
    "    column_name='contact',\n",
    "    sdtype='categorical')\n",
    "metadata.update_column(\n",
    "    column_name='day',\n",
    "    sdtype='numerical',\n",
    "    computer_representation='UInt8')\n",
    "metadata.update_column(\n",
    "    column_name='month',\n",
    "    sdtype='categorical')\n",
    "metadata.update_column(\n",
    "    column_name='duration',\n",
    "    sdtype='numerical',\n",
    "    computer_representation='Int64')\n",
    "metadata.update_column(\n",
    "    column_name='campaign',\n",
    "    sdtype='numerical',\n",
    "    computer_representation='Int32')\n",
    "metadata.update_column(\n",
    "    column_name='pdays',\n",
    "    sdtype='numerical',\n",
    "    computer_representation='Int16')\n",
    "metadata.update_column(\n",
    "    column_name='previous',\n",
    "    sdtype='numerical',\n",
    "    computer_representation='UInt16')\n",
    "metadata.update_column(\n",
    "    column_name='poutcome',\n",
    "    sdtype='categorical')\n",
    "metadata.update_column(\n",
    "    column_name='y',\n",
    "    sdtype='categorical')\n",
    "\n",
    "display(metadata.validate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67193ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(metadata)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe82e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Define dataset id and save metadata\n",
    "meta_filepath = f\"{folders['meta_dir']}{data_id}\"\n",
    "\n",
    "try:\n",
    "    metadata.save_to_json(meta_filepath)\n",
    "\n",
    "except:\n",
    "    print(f\"File {meta_filepath} already exits and has been replaced.\")\n",
    "    os.remove(meta_filepath)\n",
    "    metadata.save_to_json(meta_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset meta data for the setup parameters in pycaret\n",
    "# use this to avoid needing to save the whole dataset in a pickle object\n",
    "\n",
    "# use the parameters to read the data from csv into the setup, e.g.\n",
    "meta = {\n",
    "    # Generall\n",
    "    'name':     data_name,\n",
    "    'id':       data_id,\n",
    "    'filename': f\"{data_id}-{data_filename}\",\n",
    "    \n",
    "    'cols_dtype': cols_dtype,\n",
    "    \n",
    "    # Pycaret\n",
    "    'target': 'y',\n",
    "    \n",
    "    'categorical_features': [\n",
    "        'job',\n",
    "        'marital',\n",
    "        'default',\n",
    "        'housing',\n",
    "        'loan',\n",
    "        'contact',\n",
    "        'poutcome'\n",
    "    ],\n",
    "    \n",
    "    'ordinal_features': {\n",
    "        'education': [\"unknown\", \"primary\", \"secondary\", \"tertiary\"],\n",
    "        'month': [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
    "    },\n",
    "    \n",
    "    'numeric_features': [\n",
    "        'age',\n",
    "        'balance',\n",
    "        'day',\n",
    "        'duration',\n",
    "        'campaign',\n",
    "        'pdays',\n",
    "        'previous'\n",
    "    ],\n",
    "    'text_features': None,\n",
    "\n",
    "    'meta_filepath': meta_filepath,\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0a1b8",
   "metadata": {},
   "source": [
    "> Note on Iterative imputation that exists in pycaret:\n",
    "*Iterative imputation is a imputation method that for each feature, sets up a model to predict the missing values with the rest of the features as predictors, then repeatedly does this for each feature with missing values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3f1b4",
   "metadata": {},
   "source": [
    "### Define setup parameters for pycaret\n",
    "Use these settings to instruct for pycaret how to preprocess the data, handle the model training and evaluation. Basically the ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb32a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the setup parameters for pycaret setup function, where the details of preprocessing is defined\n",
    "# Note: can only contain keywords that exists in the settings of the pycaret.setup()\n",
    "\n",
    "setup_param = {\n",
    "    'target': meta['target'],\n",
    "\n",
    "    ### Sampling settings ###\n",
    "    'train_size': 0.8,  # (float) default=0.7, the train test split\n",
    "    # used for training and validation\n",
    "    'fold_strategy': 'stratifiedkfold',  # (srt), default = 'stratifiedkfold',\n",
    "    # selects cross-validation method\n",
    "    'fold': config['clf']['cv_folds'],  # (int) default=10, the number of folds\n",
    "\n",
    "    ### Data-preparation settings ###\n",
    "\n",
    "    #### Define features (use meta) ####\n",
    "    'ordinal_features': meta['ordinal_features'],\n",
    "    'numeric_features': meta['numeric_features'],\n",
    "    'text_features': meta['text_features'],\n",
    "    'categorical_features': meta['categorical_features'],\n",
    "\n",
    "    #### Imputation methods #### \n",
    "    #Note: imputation will be performed in step 1, instead of in pycaret\n",
    "    'imputation_type': None,  # ('simple', 'iterative', None) default='simple'\n",
    "    'numeric_imputation': 'mean',  # (int, float or str) default='mean',\n",
    "                        # it's ignored if imputation_type='iterative'\n",
    "                        # alternatives:\n",
    "                        #   'drop'      : drops rows with missing values\n",
    "                        #   'mean'      : replace with mean of column\n",
    "                        #   'median'    : replace with median of column\n",
    "                        #   'mode'      : replace with mode of column\n",
    "                        #   'knn'       : replace with KNN approach\n",
    "                        #   int or float: replace with provided value\n",
    "    'categorical_imputation': 'mode',  # same as numeric, but only with 'drop', 'mode' and str\n",
    "                                       # (replace with str)\n",
    "\n",
    "    # iterative imputation is automatically ignored if imputation_type='simple' or None\n",
    "    'iterative_imputation_iters': 10,  # (int), default=5, number of iterations\n",
    "    'numeric_iterative_imputer': 'lightgbm',  # (str or sklearn estimator), default='lightgbm',\n",
    "                                             # the regression algorithm for numeric imputation\n",
    "    'categorical_iterative_imputer': 'lightgbm',  # (str or sklearn estimator), default='lightgbm'\n",
    "\n",
    "    \n",
    "    #### Text encoding ####\n",
    "    'text_features_method': 'tf-idf',  # (str), default='tf-idf', alternative 'bow'\n",
    "    'max_encoding_ohe': 20,  # (int), default=25, cat. columns with less than specified value\n",
    "                                # will be encoded with OneHotEncoding.\n",
    "    'encoding_method': None,  # (category-encoders estimator), default=None, \n",
    "                              # for cat. cols with more unique values than 'max_encoding_ohe',\n",
    "                              # if none, then default = leave_one_out.LeaveOneOutEncoder\n",
    "\n",
    "    \n",
    "    #### Feature engineering ####\n",
    "    'low_variance_threshold': None,  # (float or none), default=None, \n",
    "                                     # variance threshold for features, features\n",
    "                                     # with lower variance are discarded -- if none, keep all features.\n",
    "    'remove_multicollinearity': False, # (bool), default=False, use correlation as threshold for feature selection\n",
    "    'multicollinearity_threshold': 0.01,  # (float), default=0.9, use if setting above is true\n",
    "    \n",
    "    'bin_numeric_features': None, # (string[]), default=None, convert numeric features into categorical.\n",
    "    'remove_outliers': False,  # (bool), default=False, remove outliers using an isolation forest.\n",
    "    'outliers_method': 'iforest',  # (string), default='iforest', alternatives:\n",
    "                                    # 'iforest': sklearn's IsolationForest\n",
    "                                    # 'ee': sklearn's EllipticEnvelope\n",
    "                                    # 'lof': sklearn's LocalOutlierFactor\n",
    "    'outliers_threshold': 0.05,  # (float), default=0.05, the percentage of outliers to be removed,\n",
    "                                # is ignored when 'remove_outliers'=False.\n",
    "    'fix_imbalance': False,  # (bool) default=False, use SMOTE to fix imbalance target features,\n",
    "                                # can specify other method with 'fix_imbalance_method'\n",
    "    'fix_imbalance_method': 'SMOTE',  # (str), default='SMOTE', estimator to use\n",
    "    \n",
    "    'transformation': False,  # (bool) default=False, if true apply power transform\n",
    "                              # to make the data more Gaussian-like\n",
    "    'transformation_method': 'yeo-johnson',  # (str), default='yeo-johnson'\n",
    "    \n",
    "    'normalize': True,  # (bool) default=False, scale data\n",
    "    'normalize_method': 'zscore',  # (str) default='zscore', alt: 'minmax'\n",
    "    \n",
    "    'pca': False,  # (bool) default=False, use principal component analysis\n",
    "                   # to reduce dimensionality\n",
    "    'pca_method': 'linear',  # (str) default='linear', alt: 'kernel', 'incremental'\n",
    "    'pca_components': None,  # (int,float,str,None) default=None, if:\n",
    "                             # * None: all components are kept\n",
    "                             # * int: the absolute number of components\n",
    "                             # * float: the variance limit for explaination\n",
    "                             # * \"mle\": use  Minka's MLE to guess dimension,\n",
    "                             #          only works with pca_method='linear'\n",
    "    'feature_selection': False,  # (bool) default=False, select features based on a\n",
    "                                    # feature importance score defined by following param\n",
    "    'feature_selection_method': 'classic',  # (str) default='classic', if\n",
    "                                    # * 'univariate': use sklearn SelectKBest\n",
    "                                    # * 'classic': use sklearn SelectFromModel\n",
    "                                    # * 'sequential': use sklearn SequentialFeatureSelector\n",
    "    'feature_selection_estimator': 'lightbm',  # (str, sklearn estimator) default='lightbm',\n",
    "                                    # the choice of classifier that decides feature importance,\n",
    "                                    # where the estimator needs to have 'feature_importances'\n",
    "                                    # or 'coef_attribute' after the fitting. If none, use\n",
    "                                    # LGBClassifier\n",
    "                                    # This param. is ignored when method='univariate'\n",
    "    'n_features_to_select': 0.2,  # (int,float) default=0.2, The max number of features\n",
    "                                    # to use with feature_selection, only looks at features\n",
    "                                    # allowed (i.e. not at 'ignore_features') when counting.\n",
    "\n",
    "    ###### Backend-settings ######\n",
    "\n",
    "    ### Logging settings ###\n",
    "    ### Note: have implmented manual loggning\n",
    "    'log_experiment': False,  # choose logger, alternatives: default='mlflow', 'wandb'\n",
    "    'experiment_name': f\"{meta['id']}-{meta['name']}\",  # The experiment name, set as the id-dataset name\n",
    "    'system_log': folders['log_dir'] + meta['id'],   # system loggin, for debugging\n",
    "    \n",
    "    #'experiment_custom_tags': {'Dataset Type': 'Original', 'Dataset ID': meta['id']},  # will be changed to 'Synthetic' when using synthetic data\n",
    "    #'log_plots': False,  # (bool) default=False, if true analysis plots are saved as image files\n",
    "    #'log_data': True,  # (bool) default=Flase, log the train & test datasets as a csv file\n",
    "\n",
    "    #### Hardware settings ####\n",
    "    'n_jobs': -1, # number of jobs to run in parallel (-1 means use all available processors)\n",
    "    'use_gpu': True, # (bool or str) default=False, whether the GPU should be used for training\n",
    "\n",
    "    ### Output settings ###\n",
    "    'html': True,  # (bool) default=True, prevents runtime display of the monitor,\n",
    "                    # disable when the env doesn't support IPYTHON\n",
    "                    # Todo: for real experiment, set verbose to false, to disable output of grids\n",
    "    'verbose': True,  # (bool) default=True, print information grid?\n",
    "    'profile': False,  # (bool) default=False, if true it displays an interactive EDA report\n",
    "    'preprocess': True,  # (bool) default=True, use preprocessing methods within pycaret?\n",
    "\n",
    "    # (something wrong with this argument, deprecated?)'silent': False, #(bool) default=False, need to be True when executed in a automated setting\n",
    "    # might not need following, because I will drop the features not neede in preperation of data\n",
    "    # ignore_features = None # (string[]) default=None, list of columns to be ignored in preporcessing and training\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de98861",
   "metadata": {},
   "source": [
    "#### Define settings for the Synthetic Data Generator\n",
    "Extracts the column names, and renames fields to field_types (because of implementation issue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTICE: is deprecated, as of SDV 1.0.0\n",
    "#field_names = data.columns.to_list()\n",
    "# Define the dataset specific parameters for the sdg CTGAN()\n",
    "# Note: can only contain keywords that are accepted by CTGAN() function in sdv\n",
    "sdg_param = {\n",
    "    # Metadata on the dataset\n",
    "    #\"field_names\": field_names,\n",
    "    #\"primary_key\": \"Outcome\",\n",
    "    \n",
    "    # same data as meta_data, however, \n",
    "    #the SDG model method uses a different parameter name\n",
    "    #\"columns\": meta['meta_data']['fields'],  \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699aa66",
   "metadata": {},
   "source": [
    "### Save for next steps\n",
    "In the cell below, the dataset meta-data and the settings for preprocessing and model creation is saved as a pickle object in its respective directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375bd79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine then save the objects to '../pickles/settings' directory \n",
    "import pickle\n",
    "\n",
    "data_settings = {\n",
    "    \"meta\": meta,\n",
    "    \"setup_param\": setup_param,\n",
    "    \"sdg_param\": sdg_param,\n",
    "}\n",
    "\n",
    "pickle.dump(\n",
    "    data_settings, \n",
    "    open(f\"{folders['settings_dir']}{meta['id']}-settings.pkl\", 'wb') \n",
    ")\n",
    "\n",
    "data.to_csv(f\"{folders['real_dir']}{meta['filename']}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if saved correctly\n",
    "cols_dtypet=None\n",
    "\n",
    "if 'cols_dtype' in meta:\n",
    "    cols_dtypedt=meta['cols_dtype']\n",
    "d = pd.read_csv(f\"{folders['real_dir']}{meta['filename']}\", dtype=cols_dtype)\n",
    "\n",
    "d.info(verbose=True, memory_usage='deep')\n",
    "d['y']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 (syn)",
   "language": "python",
   "name": "syn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
