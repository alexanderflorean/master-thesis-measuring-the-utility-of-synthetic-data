{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428e03ac",
   "metadata": {},
   "source": [
    "# Step 5: Measure Population Fidelity (PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f8125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from math import sqrt\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from PF_metrics import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6414d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'meta': {'name': 'Diabetes',\n",
       "   'id': 'D0',\n",
       "   'filename': 'diabetes.csv',\n",
       "   'target': 'Outcome',\n",
       "   'ordinal_features': None,\n",
       "   'numeric_features': ['DiabetesPedigreeFunction',\n",
       "    'BMI',\n",
       "    'Insulin',\n",
       "    'Glucose',\n",
       "    'Age',\n",
       "    'SkinThickness',\n",
       "    'BloodPressure',\n",
       "    'Pregnancies'],\n",
       "   'text_features': None,\n",
       "   'categorical_features': None,\n",
       "   'meta_data': {'fields': {'Pregnancies': {'type': 'numerical',\n",
       "      'subtype': 'integer',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'Glucose': {'type': 'numerical',\n",
       "      'subtype': 'integer',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'BloodPressure': {'type': 'numerical',\n",
       "      'subtype': 'integer',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'SkinThickness': {'type': 'numerical',\n",
       "      'subtype': 'integer',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'Insulin': {'type': 'numerical',\n",
       "      'subtype': 'integer',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'BMI': {'type': 'numerical',\n",
       "      'subtype': 'float',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'DiabetesPedigreeFunction': {'type': 'numerical',\n",
       "      'subtype': 'float',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'Age': {'type': 'numerical',\n",
       "      'subtype': 'integer',\n",
       "      'transformer': 'FloatFormatter'},\n",
       "     'Outcome': {'type': 'categorical', 'transformer': None}}},\n",
       "   'sd_meta_list': [{'id': 'SD0Q1_0',\n",
       "     'path': '../data/synthetic/SD0Q1_0.csv',\n",
       "     'sdg_params': {'epochs': 10, 'batch_size': 6, 'pac': 2, 'verbose': True}},\n",
       "    {'id': 'SD0Q2_0',\n",
       "     'path': '../data/synthetic/SD0Q2_0.csv',\n",
       "     'sdg_params': {'epochs': 300,\n",
       "      'batch_size': 50,\n",
       "      'pac': 10,\n",
       "      'verbose': True}}]},\n",
       "  'setup_param': {'target': 'Outcome',\n",
       "   'train_size': 0.8,\n",
       "   'fold_strategy': 'stratifiedkfold',\n",
       "   'fold': 10,\n",
       "   'ordinal_features': None,\n",
       "   'numeric_features': ['DiabetesPedigreeFunction',\n",
       "    'BMI',\n",
       "    'Insulin',\n",
       "    'Glucose',\n",
       "    'Age',\n",
       "    'SkinThickness',\n",
       "    'BloodPressure',\n",
       "    'Pregnancies'],\n",
       "   'text_features': None,\n",
       "   'categorical_features': None,\n",
       "   'imputation_type': 'simple',\n",
       "   'numeric_imputation': 'mean',\n",
       "   'categorical_imputation': 'mode',\n",
       "   'iterative_imputation_iters': 10,\n",
       "   'numeric_iterative_imputer': 'lightgbm',\n",
       "   'categorical_iterative_imputer': 'lightgbm',\n",
       "   'text_features_method': 'tf-idf',\n",
       "   'max_encoding_ohe': 25,\n",
       "   'encoding_method': None,\n",
       "   'low_variance_threshold': None,\n",
       "   'remove_multicollinearity': False,\n",
       "   'multicollinearity_threshold': 0.01,\n",
       "   'bin_numeric_features': None,\n",
       "   'remove_outliers': False,\n",
       "   'outliers_method': 'iforest',\n",
       "   'outliers_threshold': 0.05,\n",
       "   'fix_imbalance': False,\n",
       "   'fix_imbalance_method': 'SMOTE',\n",
       "   'transformation': False,\n",
       "   'transformation_method': 'yeo-johnson',\n",
       "   'normalize': True,\n",
       "   'normalize_method': 'zscore',\n",
       "   'pca': False,\n",
       "   'pca_method': 'linear',\n",
       "   'pca_components': None,\n",
       "   'feature_selection': False,\n",
       "   'feature_selection_method': 'classic',\n",
       "   'feature_selection_estimator': 'lightbm',\n",
       "   'n_features_to_select': 0.2,\n",
       "   'log_experiment': 'mlflow',\n",
       "   'experiment_name': 'D0-Diabetes',\n",
       "   'system_log': '../logs/D0',\n",
       "   'experiment_custom_tags': {'Dataset Type': 'Original', 'Dataset ID': 'D0'},\n",
       "   'log_plots': False,\n",
       "   'log_data': True,\n",
       "   'n_jobs': -1,\n",
       "   'use_gpu': False,\n",
       "   'html': True,\n",
       "   'verbose': True,\n",
       "   'profile': False,\n",
       "   'preprocess': True},\n",
       "  'sdg_param': {'field_names': ['Pregnancies',\n",
       "    'Glucose',\n",
       "    'BloodPressure',\n",
       "    'SkinThickness',\n",
       "    'Insulin',\n",
       "    'BMI',\n",
       "    'DiabetesPedigreeFunction',\n",
       "    'Age',\n",
       "    'Outcome'],\n",
       "   'field_types': {'Pregnancies': {'type': 'numerical',\n",
       "     'subtype': 'integer',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'Glucose': {'type': 'numerical',\n",
       "     'subtype': 'integer',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'BloodPressure': {'type': 'numerical',\n",
       "     'subtype': 'integer',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'SkinThickness': {'type': 'numerical',\n",
       "     'subtype': 'integer',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'Insulin': {'type': 'numerical',\n",
       "     'subtype': 'integer',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'BMI': {'type': 'numerical',\n",
       "     'subtype': 'float',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'DiabetesPedigreeFunction': {'type': 'numerical',\n",
       "     'subtype': 'float',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'Age': {'type': 'numerical',\n",
       "     'subtype': 'integer',\n",
       "     'transformer': 'FloatFormatter'},\n",
       "    'Outcome': {'type': 'categorical', 'transformer': None}}}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = getExperimentConfig()\n",
    "settings = getPicklesFromDir(config['folders']['settings_dir'])\n",
    "display(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618f1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"../data/real/diabetes.csv\")\n",
    "sd0q1 = pd.read_csv(\"../data/synthetic/SD0Q1_0.csv\")\n",
    "sd0q2 = pd.read_csv(\"../data/synthetic/SD0Q2_0.csv\")\n",
    "#display(sd0q1)\n",
    "#display(sd0q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01d6627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd0q1.drop(columns='Unnamed: 0', inplace=True)\n",
    "#display(sd0q1.head())\n",
    "sd0q2.drop(columns='Unnamed: 0', inplace=True)\n",
    "#display(sd0q2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254843c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples data: 1536, num_klusters:70\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Clustering algorithm could not initialize. Consider assigning the initial clusters manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m categorical_indecies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8\u001b[39m]\n\u001b[0;32m      4\u001b[0m metadata \u001b[38;5;241m=\u001b[39m settings[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m c1 \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msynthetic_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msd0q1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCluster analysis metric, SD0Q1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Log: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog(c1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m )\n",
      "File \u001b[1;32m~\\source\\repos\\master-thesis-vt23\\notebooks\\../src\\PF_metrics.py:239\u001b[0m, in \u001b[0;36mcluster_metric\u001b[1;34m(original_data, synthetic_data, num_clusters, metadata, random_state)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum samples data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combined_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_klusters:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m     kproto \u001b[38;5;241m=\u001b[39m KPrototypes(n_clusters\u001b[38;5;241m=\u001b[39mnum_clusters, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCao\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom_state, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m     \u001b[43mkproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_combined_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     cluster_labels \u001b[38;5;241m=\u001b[39m kproto\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m    243\u001b[0m original_data_count \u001b[38;5;241m=\u001b[39m original_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]    \u001b[38;5;66;03m# number of samples in original data\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\kmodes\\kprototypes.py:161\u001b[0m, in \u001b[0;36mKPrototypes.fit\u001b[1;34m(self, X, y, categorical, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m kmodes\u001b[38;5;241m.\u001b[39m_validate_sample_weight(sample_weight, n_samples\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    156\u001b[0m                                n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# If self.gamma is None, gamma will be automatically determined from\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# the data. The function below returns its value.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enc_cluster_centroids, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enc_map, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost_, \\\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_costs_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m \u001b[43mk_prototypes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dissim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat_dissim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\kmodes\\kprototypes.py:299\u001b[0m, in \u001b[0;36mk_prototypes\u001b[1;34m(X, categorical, n_clusters, max_iter, num_dissim, cat_dissim, gamma, init, n_init, verbose, random_state, n_jobs, sample_weight)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m init_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_init):\n\u001b[1;32m--> 299\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_k_prototypes_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnumattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncatattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mnum_dissim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_dissim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43minit_no\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)(\n\u001b[0;32m    306\u001b[0m         delayed(_k_prototypes_single)(Xnum, Xcat, nnumattrs, ncatattrs,\n\u001b[0;32m    307\u001b[0m                                       n_clusters, n_points, max_iter,\n\u001b[0;32m    308\u001b[0m                                       num_dissim, cat_dissim, gamma,\n\u001b[0;32m    309\u001b[0m                                       init, init_no, verbose, seed, sample_weight)\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m init_no, seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seeds))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\master\\lib\\site-packages\\kmodes\\kprototypes.py:410\u001b[0m, in \u001b[0;36m_k_prototypes_single\u001b[1;34m(Xnum, Xcat, nnumattrs, ncatattrs, n_clusters, n_points, max_iter, num_dissim, cat_dissim, gamma, init, init_no, verbose, random_state, sample_weight)\u001b[0m\n\u001b[0;32m    408\u001b[0m         init \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m init_tries \u001b[38;5;241m==\u001b[39m RAISE_INIT_TRIES:\n\u001b[1;32m--> 410\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClustering algorithm could not initialize. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider assigning the initial clusters manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         )\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Perform an initial centroid update.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ik \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_clusters):\n",
      "\u001b[1;31mValueError\u001b[0m: Clustering algorithm could not initialize. Consider assigning the initial clusters manually."
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "n_clusters = 70\n",
    "categorical_indecies = [8]\n",
    "metadata = settings[0]['meta']['meta_data']\n",
    "\n",
    "c1 = cluster_metric(original_data=original_data, \n",
    "                             synthetic_data=sd0q1, \n",
    "                             num_clusters=n_clusters, \n",
    "                             metadata=metadata)\n",
    "\n",
    "print(f\"Cluster analysis metric, SD0Q1: {c1}, Log: {log(c1)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_measures = {\n",
    "    'DatasetName',\n",
    "    'pMSE',\n",
    "    'SpMSE',\n",
    "    'Cluster_2.5',   # num of clusters = 2.5% of dataset_size\n",
    "    'Cluster_5',     # num of clusters = 5% of dataset_size\n",
    "    'Cluster_10',    # num of clusters = 10% of dataset_size\n",
    "    'BNLikelihood',\n",
    "    'BNLogLikelihood',\n",
    "    'GMLogLikelihood',\n",
    "    'KLDivergence',\n",
    "    'ContinousKLDivergence',\n",
    "    'DiscreteKLDivergence',\n",
    "    'KSComplement',\n",
    "    'CSTest',\n",
    "    'CrCl', #Cross-classification \n",
    "}  \n",
    "    \n",
    "\n",
    "\n",
    "def compute_all_pf_measures(original_data:pd.DataFrame, synthetic_data:pd.DataFrame, metadata:dict, SD_id:str) -> pd.DataFrame:\n",
    "    \n",
    "    # get number of clusters, using the combined number of samples in the synthetic & original data, \n",
    "    # and round it to an integer\n",
    "    one_percent = 0.01\n",
    "    five_percent = 0.05\n",
    "    ten_percent = 0.1\n",
    "    \n",
    "    k_1  = round( (original_data.shape[0] + synthetic_data.shape[0]) * one_percent)\n",
    "    k_5  = round( (original_data.shape[0] + synthetic_data.shape[0]) * five_percent)\n",
    "    k_10 = round( (original_data.shape[0] + synthetic_data.shape[0]) * ten_percent)\n",
    "\n",
    "    \n",
    "    measures = {\n",
    "        'DatasetName': SD_id,\n",
    "        \n",
    "        'pMSE': pmse(original_data=original_data, synthetic_data=synthetic_data),\n",
    "        \n",
    "        'SpMSE': s_pmse(original_data=original_data, synthetic_data=synthetic_data),\n",
    "        \n",
    "        'Cluster_1': cluster_metric(original_data=original_data, \n",
    "                                    synthetic_data=synthetic_data, \n",
    "                                    num_clusters=k_1, \n",
    "                                    metadata=metadata),   \n",
    "        \n",
    "        'Cluster_5': cluster_metric(original_data=original_data, \n",
    "                                    synthetic_data=synthetic_data, \n",
    "                                    num_clusters=k_5, \n",
    "                                    metadata=metadata),  \n",
    "        \n",
    "        'Cluster_10': cluster_metric(original_data=original_data, \n",
    "                                    synthetic_data=synthetic_data, \n",
    "                                    num_clusters=k_10, \n",
    "                                    metadata=metadata), \n",
    "        \n",
    "        'BNLikelihood': BNLikelihood_metric(original_data=original_data, \n",
    "                                            synthetic_data=synthetic_data, \n",
    "                                            metadata=metadata),\n",
    "        \n",
    "        'BNLogLikelihood': BNLogLikelihood_metric(original_data=original_data, \n",
    "                                                  synthetic_data=synthetic_data, \n",
    "                                                  metadata=metadata),\n",
    "        \n",
    "        'GMLogLikelihood': GmLogLikelihood_metric(original_data=original_data, \n",
    "                                                  synthetic_data=synthetic_data, \n",
    "                                                  metadata=metadata),\n",
    "\n",
    "        'ContinuousKLDivergence': ContinousKLDivergence_metric(original_data, synthetic_data, metadata),\n",
    "        'DiscreteKLDivergence': DiscreteKLDivergence_metric(original_data, synthetic_data, metadata),\n",
    "        'KSComplement': KSComplement_metric(original_data, synthetic_data, metadata),\n",
    "        'CSTest': CSTest_metric(original_data, synthetic_data, metadata),\n",
    "        'CrossClassification': CrossClassification_metric(original_data, synthetic_data, metadata)\n",
    "    }\n",
    "    \n",
    "    results_df = pd.DataFrame(data=measures, index=0)\n",
    "    return results_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395c5fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta = settings[0]['meta']['meta_data']\n",
    "pf_measures = compute_all_pf_measures(original_data=original_data,\n",
    "                                      synthetic_data=sd0q1,\n",
    "                                      metadata=meta,\n",
    "                                      SD_id='SD0Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pf_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4552d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spmse1 = s_pmse(original_data, sd0q1)\n",
    "spmse2 = s_pmse(original_data, sd0q2)\n",
    "print(f\"S_pMSE: SD0Q1: {spmse1}, SD0Q2: {spmse2}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(sd0q1.head())\n",
    "r1 = pmse(original_data, sd0q1)\n",
    "r2 = pmse(original_data, sd0q2)\n",
    "print(f\"pMSE: SD0Q1: {r1}, SD0Q2: {r2}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bb623",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sdmetrics.reports.single_table import QualityReport, DiagnosticReport\n",
    "q1Report = QualityReport()\n",
    "q2Report = QualityReport()\n",
    "\n",
    "d1Report = DiagnosticReport()\n",
    "d2Report = DiagnosticReport()\n",
    "meta = settings[0]['meta']['meta_data']\n",
    "\n",
    "display(\"SD0Q1\")\n",
    "# d1Report.generate(original_data, sd0q1, metadata)\n",
    "q1Report.generate(original_data, sd0q1, meta)\n",
    "display(q1Report.get_details(property_name='Column Shapes'))\n",
    "\n",
    "display(\"SD0Q2\")\n",
    "# d2Report.generate(original_data, sd0q2, metadata)\n",
    "q2Report.generate(original_data, sd0q2, meta)\n",
    "display(q2Report.get_details(property_name='Column Shapes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(\"SD0Q1\")\n",
    "# d1fig = d1Report.get_visualization(property_name='Coverage')\n",
    "# d1fig.show()\n",
    "# q1fig = q1Report.get_visualization(property_name='Column Shapes')\n",
    "# q1fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f34361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(\"SD0Q2\")\n",
    "# d2fig = d2Report.get_visualization(property_name='Coverage')\n",
    "# d2fig.show()\n",
    "# q2fig = q2Report.get_visualization(property_name='Column Shapes')\n",
    "# q2fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdmetrics.reports import utils\n",
    "\n",
    "fig = utils.get_column_pair_plot(\n",
    "    real_data=original_data,\n",
    "    synthetic_data=sd0q1,\n",
    "    column_names= ['Glucose', 'Age'],\n",
    "    metadata=metadata\n",
    "    \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e4deeb",
   "metadata": {},
   "source": [
    "Method to find optimal number of clusters for the clustering model using the silhouette analysis method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from kmodes.kprototypes import KPrototypes\n",
    "#from sklearn.metrics import silhouette_score\n",
    "#import matplotlib.pyplot as plt\n",
    "#\n",
    "#n_clusters = 20\n",
    "#\n",
    "#o_data = original_data.copy()\n",
    "##o_data['S'] = 0\n",
    "#\n",
    "#s_data = sd0q1.copy()\n",
    "##s_data['S'] = 1\n",
    "#\n",
    "#\n",
    "#combined_data = pd.concat([o_data, s_data], axis=0)\n",
    "#scaled_combined_data = standardize_select_columns(combined_data, [8])\n",
    "#\n",
    "#silhouette_scores = []\n",
    "#\n",
    "#k_range = range(2, 50)\n",
    "#\n",
    "#for k in k_range:\n",
    "#\n",
    "#    kproto = KPrototypes(n_clusters=k, init='Cao').fit(scaled_combined_data, categorical=[8])\n",
    "#    silhouette_scores.append(silhouette_score(scaled_combined_data, kproto.labels_))\n",
    "#\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.plot(k_range, silhouette_scores, 'bx-')\n",
    "#ax.set_title('Silhouette Score Method')\n",
    "#ax.set_xlabel('Number of clusters')\n",
    "#ax.set_ylabel('Silhouette Scores')\n",
    "#plt.xticks(k_range)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed378bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "## check implementation of cluster analysis\n",
    "#o_data = original_data.copy()\n",
    "#o_data['S'] = 0\n",
    "#\n",
    "#s_data = sd0q1.copy()\n",
    "#s_data['S'] = 1\n",
    "#\n",
    "#\n",
    "#combined_data = pd.concat([o_data, s_data], axis=0)\n",
    "#scaled_combined_data = standardize_select_columns(combined_data, [8])\n",
    "#\n",
    "#k=4\n",
    "#kproto = KPrototypes(n_clusters=k, init='Cao').fit(scaled_combined_data, categorical=[8])\n",
    "#\n",
    "#cluster_labels = kproto.labels_\n",
    "#\n",
    "#original_data_count = o_data.shape[0]    # number of samples in original data\n",
    "#synthetic_data_count = s_data.shape[0]  # number of samples in synthetic data\n",
    "#total_data_count = original_data_count + synthetic_data_count\n",
    "#\n",
    "#constant_c = original_data_count / (original_data_count + synthetic_data_count)\n",
    "#\n",
    "#display(cluster_labels)\n",
    "#\n",
    "#\n",
    "#scaler = StandardScaler()\n",
    "#column_indices = np.arange(combined_data.shape[1])\n",
    "#\n",
    "#columns_to_standardize = np.setdiff1d(column_indices, [8,9])\n",
    "#\n",
    "#combined_data.iloc[:, columns_to_standardize] = scaler.fit_transform(combined_data.iloc[:, columns_to_standardize])\n",
    "#\n",
    "##for cluster_id in range(k):\n",
    "##\n",
    "##    # TODO: add column, and identify dataset sample from the cluster\n",
    "##    original_cluster_data_count = np.sum(cluster_labels[:original_data_count] == cluster_id)\n",
    "##    synthetic_cluster_data_count = np.sum(cluster_labels[original_data_count:] == cluster_id)\n",
    "##\n",
    "##    total_cluster_data_count = original_cluster_data_count + synthetic_cluster_data_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.16 (Master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
